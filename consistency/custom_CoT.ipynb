{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('/home/pervinco/LLM-tutorials/keys.env')\n",
    "openai_api_key = os.getenv('GRAVY_LAB_OPENAI')\n",
    "\n",
    "from src.data_processor import translate_and_convert_to_string, process_vision_result, extract_workstyle_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "temperature = 0.1\n",
    "gt_path = \"./data/amy_gt.json\"\n",
    "data_path = \"./data/amy_culture_fit.json\"\n",
    "embed_model = \"text-embedding-3-large\"\n",
    "\n",
    "output_dir = \"./result\"\n",
    "csv_file_name = f\"CoT_N-{n_iter}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, 'r', encoding='utf-8') as file:\n",
    "    hr_data_dict = json.load(file)\n",
    "\n",
    "with open(data_path, 'r', encoding=\"utf-8\") as file:\n",
    "    gt_data_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_summary = translate_and_convert_to_string(hr_data_dict['summaryResult'])\n",
    "vision_data = process_vision_result(hr_data_dict['visionResult'], hr_data_dict['summaryResult'])\n",
    "workstyle_data = extract_workstyle_info(hr_data_dict['workstyleResult'], hr_data_dict['summaryResult'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "채용 권장 수준, 입사 후 적응 기간, 조기 퇴사 가능성 : \n",
      "조기 퇴사 가능성: 낮음\n",
      "입사 후 적응 기간: 보통\n",
      "채용 권장 수준: 보통\n",
      "\n",
      "검사 항목별 결과 : \n",
      "5) 사고방식이 기업 비전,가치관에 부합하는가?: 매우 그렇다\n",
      "2) 타 팀, 타 구성원과의 원만한 협업을 기대할 수 있는가?: 그렇다\n",
      "3) 경영진, 상급자와의 원활한 소통을 기대할 수 있는가?: 그렇다\n",
      "4) 기업이 추구하는 일하는 방식과 부합하는가?: 매우 그렇다\n",
      "1) 구성원들과 원활한 소통이 가능한가?: 그렇다\n",
      "\n",
      "이직 스트레스 요인 : \n",
      "공정인사\n",
      "\n",
      "위험 성향 : 오만형\n"
     ]
    }
   ],
   "source": [
    "print(processed_data_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company_top_keywords': '전문성:4.6, 성과:4.2, 사회공헌:4.2', 'company_remaining_keywords': '상생:4.0, 최고지향:3.6, 고객:3.0, 성장:3.0', 'compute_top_keywords': '창조:5.0, 열정:5.0, 혁신:4.58', 'compute_remaining_keywords': '신속성:4.23, 사회공헌:4.17, 고객:4.0, 성장:3.85, 소통:3.75, 성과:3.33, 도전:3.21, 상생:3.13, 최고지향:2.78, 문제해결:2.5, 인재:2.27, 즐거움:1.5, 전문성:0.38', 'compute_vision_total_evalation': '보통'}\n"
     ]
    }
   ],
   "source": [
    "print(vision_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company_keywords': '스피드형:3.2, 책임형:2.7, 목표지향형:4.0, 끈기형:3.0, 긍정형:3.5, 유니크형:2.9, 혁신형:3.4, 도전형:3.0, 스마트형:3.5, 윤리형:2.2, 성취형:2.2, 열린사고형:3.3, 솔선수범형:3.5, 몰입형:4.3, 신뢰형:1.8, 자기확신형:2.7', 'compute_keywords': '스피드형:4.33, 책임형:0.63, 목표지향형:3.33, 끈기형:0.67, 긍정형:2.5, 유니크형:5.0, 혁신형:5.0, 도전형:3.5, 스마트형:2.75, 윤리형:1.25, 성취형:3.44, 열린사고형:3.75, 솔선수범형:1.88, 몰입형:3.44, 신뢰형:0.65, 자기확신형:3.0', 'workstyle_match_percentage': 18.75, 'workstyle_company_total_score': 49.2, 'workstyle_compute_total_score': 45.12, 'comparison_ratio': 91.70731707317073, 'compute_workstyle_total_evalation': '우수'}\n",
      "company_keywords 스피드형:3.2, 책임형:2.7, 목표지향형:4.0, 끈기형:3.0, 긍정형:3.5, 유니크형:2.9, 혁신형:3.4, 도전형:3.0, 스마트형:3.5, 윤리형:2.2, 성취형:2.2, 열린사고형:3.3, 솔선수범형:3.5, 몰입형:4.3, 신뢰형:1.8, 자기확신형:2.7\n",
      "compute_keywords 스피드형:4.33, 책임형:0.63, 목표지향형:3.33, 끈기형:0.67, 긍정형:2.5, 유니크형:5.0, 혁신형:5.0, 도전형:3.5, 스마트형:2.75, 윤리형:1.25, 성취형:3.44, 열린사고형:3.75, 솔선수범형:1.88, 몰입형:3.44, 신뢰형:0.65, 자기확신형:3.0\n",
      "workstyle_match_percentage 18.75\n",
      "workstyle_company_total_score 49.2\n",
      "workstyle_compute_total_score 45.12\n",
      "comparison_ratio 91.70731707317073\n",
      "compute_workstyle_total_evalation 우수\n"
     ]
    }
   ],
   "source": [
    "print(workstyle_data)\n",
    "\n",
    "for k, v in workstyle_data.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_prompt = \"\"\"\n",
    "주어진 데이터는 기업 비전과 피검사자의 비전 점수를 기반으로 분석한 결과입니다. 다음은 분석 단계입니다:\n",
    "\n",
    "1. **기업의 비전 상위 3개 선별**:\n",
    "   기업의 비전에서 점수가 높은 상위 3개의 키워드를 선택합니다. 예를 들어, [\"전문성\", \"사회공헌\", \"성과\"]와 같이 구성됩니다.\n",
    "\n",
    "2. **피검사자의 비전 상위 3개 선별**:\n",
    "   피검사자의 비전에서 점수가 높은 상위 3개의 키워드를 선택합니다. 예를 들어, [\"창조\", \"열정\", \"혁신\"]와 같이 구성됩니다.\n",
    "\n",
    "3. **동일 키워드 점수 차이 분석**:\n",
    "   기업과 피검사자 상위 3개 키워드 중 동일한 키워드가 있을 경우, 두 점수의 차이를 계산합니다. 이를 \"equal_top3\"라 부릅니다. 차이가 큰 경우 우려를 표현하며, 차이가 작은 경우 긍정적인 평가를 제공합니다. 예를 들어:\n",
    "   - \"전문성\" (기업: 4.6, 피검사자: 0.38) → 큰 차이로 인해 우려 사항.\n",
    "   - \"사회공헌\" (기업: 4.2, 피검사자: 4.17) → 매우 유사함으로 긍정 평가.\n",
    "\n",
    "4. **일치하지 않는 키워드 분석**:\n",
    "   기업 상위 3개 키워드와 일치하지 않는 피검사자의 상위 키워드를 \"noeq_top3\"로 구분합니다. 이를 통해 피검사자가 독자적으로 높은 관심을 가진 비전을 파악합니다. 예를 들어, \"창조\", \"열정\".\n",
    "\n",
    "5. **결과 서술**:\n",
    "   - 기업이 중요시하는 비전과 피검사자가 중요시하는 비전을 각각 서술합니다.\n",
    "   - \"equal_top3\"에서 차이가 1.8 이상인 키워드에 대해 우려를 표현하되, 부정적인 내용은 피합니다.\n",
    "   - \"equal_top3\"에서 차이가 0.5 이하인 경우 긍정적으로 표현합니다.\n",
    "   - 피검사자의 점수가 기업보다 높은 경우, 강한 긍정과 추가적 가치 창출 가능성을 언급합니다.\n",
    "\n",
    "6. **최종 결과 문장 생성**:\n",
    "   300자 이내의 문장으로 피검사자가 기업 비전과 어느 정도 정렬되어 있는지를 서술합니다. \n",
    "   반드시 존댓말을 사용하며, 피검사자가 기업에 적합한지 겸손한 어조로 표현합니다. \n",
    "   문장의 끝부분에는 \"전반적으로 피검사자와 기업간 비전 fit은 [높음, 보통, 낮은] 편입니다.\" 로 마무리 지어 주세요.\n",
    "   또한 아래 예시를 참고하여 작성합니다:\n",
    "\n",
    "   \"기업은 전문성, 성과, 사회공헌을 중요시하며, 피검사자는 창조, 열정, 혁신에 높은 가치를 두고 있습니다. 피검사자는 사회공헌에 대한 관심이 기업과 유사하며, 이는 긍정적으로 평가됩니다. 그러나 전문성에 대한 피검사자의 관심이 상대적으로 낮아 우려가 있을 수 있습니다. 반면, 피검사자는 성과에 대한 관심이 기업보다 낮지만, 창조와 열정에서 높은 점수를 보이며 기업에 추가적인 가치를 제공할 가능성이 있습니다. 전반적으로 피검사자와 기업간 비전 fit은 보통입니다.\"\n",
    "\"\"\"\n",
    "\n",
    "workstyle_prompt = \"\"\"\n",
    "목표: 기업이 중요하게 생각하는 업무 스타일을 기준으로 피검사자의 업무 스타일이 얼마나 일치하는지를 평가하는 문장을 작성하는 것입니다. 이 문장은 피검사자가 기업의 업무 스타일에 적합한지를 평가하여 조직 적응 가능성을 판단하는 데 사용됩니다.\n",
    "\n",
    "작업 설명: 다음 과정을 따라 피검사자가 기업의 업무 스타일에 얼마나 잘 맞는지를 평가하는 문장을 작성하세요.\n",
    "\n",
    "과정:\n",
    "1. 기업의 업무 성향 키워드 점수와 피검사자의 업무 성향 키워드 점수 간 차이를 계산합니다. 차이를 계산한 결과를 `ws_score_diff`라는 딕셔너리에 저장합니다. (`ws_score_diff = (키워드: company 점수 - compute 점수)` 형식)\n",
    "2. `ws_score_diff`에서 점수 차이가 0.5 이하인 키워드에 대해 다음 문장을 생성합니다:\n",
    "   - 점수 차이가 0 이상이면: \"피검사자는 (점수 차이가 0.5 이하인 키워드들)에서 기업의 기대치를 충족하여 긍정적 평가를 받을 수 있습니다.\"\n",
    "   - 점수 차이가 음수이면: \"피검사자는 점수 차이가 음수인 키워드들에서 기업의 기대치를 초과하여 매우 긍정적 평가를 받을 수 있습니다.\"\n",
    "   - 두 개의 결과를 종합해서 하나의 문장을 생성합니다.\n",
    "3. `ws_score_diff`에서 점수 차이가 1.8 이상인 키워드에 대해 다음 문장을 생성합니다:\n",
    "   - \"(점수차가 1.8이상인 키워드들)에 대해 기업의 기대치와 차이가 있습니다.\"\n",
    "4. `compute_workstyle_total_evaluation` 값(“우수”, “보통”, “검토필요”)에 따라 전반적인 fit 평가를 추가합니다:\n",
    "   - \"우수\": \"전반적으로 피검사자와 기업간 업무 성향 fit은 높은 편입니다.\"\n",
    "   - \"보통\": \"전반적으로 피검사자와 기업간 업무 성향 fit은 보통입니다.\"\n",
    "   - \"검토필요\": \"전반적으로 피검사자와 기업간 업무 성향 fit은 낮은 편입니다.\"\n",
    "5. 과정 2, 3, 4에서 생성된 문장을 종합하여 300자 이내로 작성합니다. \n",
    "\n",
    "중요 사항:\n",
    "- 문장은 한글로 작성하며, 항상 존댓말을 사용하세요.\n",
    "- 피검사자 점수가 기업 점수보다 높을 경우 이를 긍정적으로 표현하세요. (\"약간의 차이\" 또는 부정적인 뉘앙스는 피해주세요.)\n",
    "- 각 키워드는 제공된 명칭 그대로 사용하고, 점수를 문장에 포함하지 마세요.\n",
    "- 동일한 문장을 반복하지 않고 간결하고 명확하게 작성하세요.\n",
    "- 최종 문장의 글자 수는 300자를 초과하지 않도록 주의하세요.\n",
    "\n",
    "최종 출력: 피검사자가 기업의 업무 스타일에 얼마나 잘 맞는지 평가한 한 문장을 반환합니다. 이 문장은 피검사자의 적합성과 차이를 설명하며 fit 평가를 포함합니다.\n",
    "\"\"\"\n",
    "\n",
    "summary_prompt = \"\"\"\n",
    "목표: 채용 피검사자의 결과를 바탕으로, 피검사자가 해당 기업에 얼마나 적합한지 종합적으로 평가하고, 채용 여부를 결정하는 데 필요한 코멘트를 작성하는 것입니다.\n",
    "\n",
    "작업 설명: 피검사자의 평가 데이터를 분석하고, 단계별로 정보를 종합하여 최종적으로 200자 이내의 코멘트를 작성합니다. 모든 문장은 한글로 작성하고, 존댓말과 겸손한 어체를 사용하며, 띄어쓰기를 포함하여 200자 이내로 제한해야 합니다.\n",
    "\n",
    "주의 사항: 단계별로 결과를 도출하지만, 반환하는 값은 5단계에서 생성한 최종 코멘트만 반환해야합니다. 5단계를 제외한 다른 단계의 결과를 반환하지 않도록 주의하세요.\n",
    "\n",
    "---\n",
    "\n",
    "**1단계:**  \n",
    "- \"recruitentQuestions\" 값에서 [\"그렇다\", \"매우 그렇다\"]에 해당하는 항목들을 기반으로 피검사자가 가진 긍정적인 점을 서술하세요.  \n",
    "- 예: \"피검사자는 팀 내 협력과 소통에서 긍정적인 평가를 받았습니다.\"\n",
    "\n",
    "**2단계:**  \n",
    "- \"fued\" 값이 피검사자의 갈등 유발 요인을 나타냅니다.  \n",
    "- 갈등 유발 요인이 있을 경우, 조직 내에서 발생할 수 있는 문제와 갈등을 강하게 경고하는 문장을 작성하세요.  \n",
    "- \"fued\" 값이 \"없음\"일 경우, 해당 단계는 생략하고 다음 단계로 넘어갑니다.  \n",
    "- 예: \"투쟁형 성향으로 인해 과도한 경쟁과 갈등이 우려되며, 팀 분위기에 부정적인 영향을 미칠 수 있습니다.\"\n",
    "\n",
    "**3단계:**  \n",
    "- \"turnOverFactors\" 값이 \"없음\"이 아닐 경우, \"OO에 대한 스트레스 요인이 있으므로,\"로 시작하여 기업이 대응할 수 있는 방법을 제시하세요.  \n",
    "- 확정적인 어체를 피하고, \"필요할 수 있습니다\"와 같은 제시형 어체를 사용하세요.  \n",
    "- \"turnOverFactors\" 값이 \"없음\"일 경우, 해당 단계는 생략하고 다음 단계로 넘어갑니다.  \n",
    "- 예: \"공정인사에 대한 스트레스 요인이 있으므로, 인사정책에 대한 명확한 안내가 필요할 수 있습니다.\"\n",
    "\n",
    "**4단계:**  \n",
    "- \"additionalInformation\" 값 중 \"입사 후 적응 기간\"과 \"조기 퇴사 가능성\"을 활용해 간략히 서술하세요.  \n",
    "- 예: \"입사 후 적응 기간은 보통이며, 조기 퇴사 가능성은 낮습니다.\"\n",
    "\n",
    "**5단계:**  \n",
    "- 1, 2, 3, 4단계에서 도출한 결과를 종합하여, 200자 이내로 최종 코멘트를 작성하세요.  \n",
    "- 존댓말과 겸손한 어체를 사용하며, \"채용을 권장합니다\" 또는 \"채용을 권장하지 않습니다\"와 같은 끝맺음 문장은 사용하지 않습니다.  \n",
    "- 예: \"피검사자는 기업의 비전과 가치관에 잘 부합하며, 타 팀 및 구성원과의 협업과 소통에서도 긍정적인 평가를 받았습니다. 그러나 오만형 성향이 감지되어 팀원 간 신뢰를 저해하고 적대적인 분위기를 형성할 수 있습니다. 이는 조직 내 갈등을 유발할 수 있으므로 주의가 필요합니다. 공정인사에 대한 스트레스 요인이 있으므로, 인사 정책에 대한 명확한 안내가 필요할 수 있습니다. 입사 후 적응 기간은 보통이며, 조기 퇴사 가능성은 낮습니다.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_input = f\"\"\"\n",
    "기업의 비전 데이터: {hr_data_dict[\"visionResult\"]['company']}\n",
    "피검사자의 비전 데이터: {hr_data_dict[\"visionResult\"]['compute']}\n",
    "\"\"\"\n",
    "\n",
    "workstyle_input = f\"\"\"\n",
    "company_keywords : {workstyle_data['company_keywords']}\n",
    "compute_keywords : {workstyle_data['compute_keywords']}\n",
    "workstyle_company_total_score : {workstyle_data['workstyle_company_total_score']}\n",
    "workstyle_compute_total_score : {workstyle_data['workstyle_compute_total_score']}\n",
    "workstyle_compute_total_score : {workstyle_data['workstyle_match_percentage']}\n",
    "comparison_ratio: {workstyle_data['comparison_ratio']}\n",
    "compute_workstyle_total_evaluation : {workstyle_data['compute_workstyle_total_evalation']}\n",
    "\"\"\"\n",
    "\n",
    "summary_input = f\"\"\"\n",
    "additionalInformation : {hr_data_dict['summaryResult']['additionalInformation']}\n",
    "recruitentQuestions : {hr_data_dict['summaryResult']['recruitentQuestions']}\n",
    "turnOVerFactors : {hr_data_dict['summaryResult']['turnOverFactors']}\n",
    "fued :{hr_data_dict['summaryResult']['fued']}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_openai_api(n_iter, prompt, input, temperature):\n",
    "    results = []\n",
    "    for i in range(n_iter):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": input}\n",
    "            ],\n",
    "            temperature=temperature\n",
    "        )\n",
    "        response_content = completion.choices[0].message.content\n",
    "        results.append({\n",
    "            \"iteration\": i + 1,\n",
    "            \"response\": response_content\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company top3 : 전문성:4.6, 성과:4.2, 사회공헌:4.2\n",
      "\n",
      "compute top3 : 창조:5.0, 열정:5.0, 혁신:4.58\n",
      "\n",
      "compnay remain : 상생:4.0, 최고지향:3.6, 고객:3.0, 성장:3.0\n",
      "\n",
      "compute remain : 신속성:4.23, 사회공헌:4.17, 고객:4.0, 성장:3.85, 소통:3.75, 성과:3.33, 도전:3.21, 상생:3.13, 최고지향:2.78, 문제해결:2.5, 인재:2.27, 즐거움:1.5, 전문성:0.38\n",
      "\n",
      "fianl eval : 보통\n"
     ]
    }
   ],
   "source": [
    "print(f\"company top3 : {vision_data['company_top_keywords']}\\n\")\n",
    "print(f\"compute top3 : {vision_data['compute_top_keywords']}\\n\")\n",
    "\n",
    "print(f\"compnay remain : {vision_data['company_remaining_keywords']}\\n\")\n",
    "print(f\"compute remain : {vision_data['compute_remaining_keywords']}\\n\")\n",
    "\n",
    "print(f\"fianl eval : {vision_data['compute_vision_total_evalation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_results = run_openai_api(n_iter, vision_prompt, vision_input, temperature)\n",
    "workstyle_results = run_openai_api(n_iter, workstyle_prompt, workstyle_input, temperature)\n",
    "summary_results = run_openai_api(n_iter, summary_prompt, summary_input, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_dataframe(vision_results, workstyle_results):\n",
    "    \"\"\"Create separate dataframes for vision and workstyle results\"\"\"\n",
    "    vision_df = pd.DataFrame(vision_results)\n",
    "    vision_df['type'] = 'vision'\n",
    "\n",
    "    workstyle_df = pd.DataFrame(workstyle_results)\n",
    "    workstyle_df['type'] = 'workstyle'\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_results)\n",
    "    summary_df['type'] = 'summary'\n",
    "    \n",
    "    # Combine the dataframes\n",
    "    combined_df = pd.concat([vision_df, workstyle_df, summary_df], ignore_index=True)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./result/CoT_N-1.csv\n"
     ]
    }
   ],
   "source": [
    "df = create_results_dataframe(vision_results, workstyle_results)\n",
    "df.to_csv(os.path.join(output_dir, csv_file_name), index=False, encoding='utf-8-sig')\n",
    "print(f\"Results saved to {os.path.join(output_dir, csv_file_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{output_dir}/{csv_file_name}\")\n",
    "responses = df[\"response\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding_similarity_and_embeddings(responses, client):\n",
    "    embeddings = []\n",
    "    for response in responses:\n",
    "        embedding_response = client.embeddings.create(\n",
    "            input=response,\n",
    "            model=embed_model\n",
    "        )\n",
    "        embeddings.append(embedding_response.data[0].embedding)\n",
    "\n",
    "    embeddings = np.array(embeddings)\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    mean_similarity = similarity_matrix.mean()\n",
    "    \n",
    "    return mean_similarity, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lexical_similarity(responses):\n",
    "    \"\"\"Calculate lexical overlap between responses\"\"\"\n",
    "    def lexical_overlap(response1, response2):\n",
    "        words1 = set(response1.split())\n",
    "        words2 = set(response2.split())\n",
    "        return len(words1 & words2) / len(words1 | words2)\n",
    "    \n",
    "    lexical_similarities = [\n",
    "        lexical_overlap(responses[i], responses[j])\n",
    "        for i in range(len(responses)) for j in range(i + 1, len(responses))\n",
    "    ]\n",
    "    mean_lexical_similarity = sum(lexical_similarities) / len(lexical_similarities)\n",
    "    return mean_lexical_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_responses(df, client):\n",
    "    \"\"\"Analyze responses for each type (vision and workstyle)\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for response_type in ['vision', 'workstyle', 'summary']:\n",
    "        type_responses = df[df['type'] == response_type]['response'].tolist()\n",
    "        \n",
    "        # Calculate semantic similarity\n",
    "        mean_similarity, embeddings = calculate_embedding_similarity_and_embeddings(type_responses, client)\n",
    "        \n",
    "        # Calculate lexical similarity\n",
    "        mean_lexical_similarity = calculate_lexical_similarity(type_responses)\n",
    "        \n",
    "        results[response_type] = {\n",
    "            'semantic_similarity': mean_similarity,\n",
    "            'lexical_similarity': mean_lexical_similarity,\n",
    "            'embeddings': embeddings\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Analyze responses\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m analysis_results \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_responses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Print results for both types\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response_type, metrics \u001b[38;5;129;01min\u001b[39;00m analysis_results\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[19], line 12\u001b[0m, in \u001b[0;36manalyze_responses\u001b[0;34m(df, client)\u001b[0m\n\u001b[1;32m      9\u001b[0m     mean_similarity, embeddings \u001b[38;5;241m=\u001b[39m calculate_embedding_similarity_and_embeddings(type_responses, client)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Calculate lexical similarity\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     mean_lexical_similarity \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_lexical_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype_responses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     results[response_type] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemantic_similarity\u001b[39m\u001b[38;5;124m'\u001b[39m: mean_similarity,\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlexical_similarity\u001b[39m\u001b[38;5;124m'\u001b[39m: mean_lexical_similarity,\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m: embeddings\n\u001b[1;32m     18\u001b[0m     }\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "Cell \u001b[0;32mIn[18], line 12\u001b[0m, in \u001b[0;36mcalculate_lexical_similarity\u001b[0;34m(responses)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(words1 \u001b[38;5;241m&\u001b[39m words2) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(words1 \u001b[38;5;241m|\u001b[39m words2)\n\u001b[1;32m      8\u001b[0m lexical_similarities \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     lexical_overlap(responses[i], responses[j])\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(responses)) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(responses))\n\u001b[1;32m     11\u001b[0m ]\n\u001b[0;32m---> 12\u001b[0m mean_lexical_similarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlexical_similarities\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlexical_similarities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mean_lexical_similarity\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# Analyze responses\n",
    "analysis_results = analyze_responses(df, client)\n",
    "\n",
    "# Print results for both types\n",
    "for response_type, metrics in analysis_results.items():\n",
    "    print(f\"\\nResults for {response_type.upper()}:\")\n",
    "    print(f\"Semantic Similarity (mean): {metrics['semantic_similarity']:.2f}\")\n",
    "    print(f\"Lexical Overlap (mean): {metrics['lexical_similarity']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
