{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pervinco/miniconda3/envs/nlp-project/lib/python3.9/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/pervinco/miniconda3/envs/nlp-project/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/pervinco/miniconda3/envs/nlp-project/lib/python3.9/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../keys.env\")\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = \"Bingsu/ko_alpaca_data\" ## \"nlpai-lab/kullm-v2\"\n",
    "model_id = \"beomi/Llama-3-Open-Ko-8B\" ## \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "val_size = 0.005\n",
    "max_seq_len = 256 ## 4098\n",
    "train_on_inputs = True\n",
    "add_eos_token = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pervinco/miniconda3/envs/nlp-project/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(data_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|>', '<|end_of_text|>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos = tokenizer.bos_token_id\n",
    "eos = tokenizer.eos_token_id\n",
    "\n",
    "tokenizer.pad_token_id = eos\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 49620\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>건강을 유지하기 위한 세 가지 팁을 알려주세요.</td>\n",
       "      <td></td>\n",
       "      <td>세 가지 팁은 아침식사를 꼭 챙기며, 충분한 수면을 취하고, 적극적으로 운동을 하는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>세 가지 기본 색은 무엇인가요?</td>\n",
       "      <td></td>\n",
       "      <td>기본 색은 빨강, 파랑, 노랑입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>원자의 구조를 설명하세요.</td>\n",
       "      <td></td>\n",
       "      <td>원자는 양성자, 중성자, 전자로 구성되어 있으며, 양성자와 중성자는 원자핵 안에 있...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>대기 오염을 어떻게 줄일 수 있나요?</td>\n",
       "      <td></td>\n",
       "      <td>대기 오염을 줄이기 위해 자동차 대신 대중교통을 이용하고, 미세먼지 배출량을 줄이기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>어려운 결정을 내려야 했던 때를 설명하세요.</td>\n",
       "      <td></td>\n",
       "      <td>제가 어려운 결정을 내려야 했던 때는 대학원 졸업 후 직장을 찾아야 했던 때입니다....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  instruction input  \\\n",
       "0  건강을 유지하기 위한 세 가지 팁을 알려주세요.         \n",
       "1           세 가지 기본 색은 무엇인가요?         \n",
       "2              원자의 구조를 설명하세요.         \n",
       "3        대기 오염을 어떻게 줄일 수 있나요?         \n",
       "4    어려운 결정을 내려야 했던 때를 설명하세요.         \n",
       "\n",
       "                                              output  \n",
       "0  세 가지 팁은 아침식사를 꼭 챙기며, 충분한 수면을 취하고, 적극적으로 운동을 하는...  \n",
       "1                               기본 색은 빨강, 파랑, 노랑입니다.  \n",
       "2  원자는 양성자, 중성자, 전자로 구성되어 있으며, 양성자와 중성자는 원자핵 안에 있...  \n",
       "3  대기 오염을 줄이기 위해 자동차 대신 대중교통을 이용하고, 미세먼지 배출량을 줄이기...  \n",
       "4  제가 어려운 결정을 내려야 했던 때는 대학원 졸업 후 직장을 찾아야 했던 때입니다....  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset['train'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10658\n",
      "input : \n",
      "\n",
      "\n",
      "\n",
      "instruction : \n",
      "\"자선\"이라는 단어가 포함된 유효한 영어 문장의 예를 제시하세요.\n",
      "\n",
      "\n",
      "output : \n",
      "영어 문장 : My sister is a volunteer at a charity organisation. (나의 누나는 자선 단체의 봉사자입니다.)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "rand_idx = randint(0, df.shape[0])\n",
    "sample_row = df.iloc[rand_idx]\n",
    "\n",
    "print(rand_idx)\n",
    "print(f\"input : \\n{sample_row['input']}\\n\\n\")\n",
    "print(f\"instruction : \\n{sample_row['instruction']}\\n\\n\")\n",
    "print(f\"output : \\n{sample_row['output']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "template = {\n",
    "    \"prompt_input\": \"아래는 문제를 설명하는 지시사항과 구체적인 답변 방식을 요구하는 입력이 함께 있는 문장입니다. 이 요청에 대해 적절하게 답변해주세요.\\n###입력:{input}\\n###지시사항:{instruction}\\n###답변:\",\n",
    "    \"prompt_no_input\": \"아래는 문제를 설명하는 지시사항입니다. 이 요청에 대해 적절하게 답변해주세요.\\n###지시사항:{instruction}\\n###답변:\"\n",
    "}\n",
    "\n",
    "def generate_prompt(instruction : str, input : Union[None, str]=None, label : Union[None, str]=None, verbose : bool = False):\n",
    "    if input:\n",
    "        result = template[\"prompt_input\"].format(instruction=instruction, input=input)\n",
    "    else:\n",
    "        result = template[\"prompt_no_input\"].format(instruction=instruction)\n",
    "\n",
    "    if label:\n",
    "        result = f\"{result}{label}\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(result)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(prompt, max_seq_len, add_eos_token=True):\n",
    "    result = tokenizer(prompt, \n",
    "                       truncation=True, ## 최대 길이를 초과하는 경우 자르기 수행\n",
    "                       max_length=max_seq_len, ## 최대 시퀀스 길이 설정\n",
    "                       padding=False, ## 패딩 비활성화. True로 설정하면 배치 내 모든 시퀀스가 max_length에 맞춰짐\n",
    "                       return_tensors=None)\n",
    "    \n",
    "    ## 토큰화된 시퀀스 데이터의 마지막이 eos 토큰이 아니며, 시퀀스 길이가 max_seq_len보다 작고, add_eos_token이 True일 경우\n",
    "    ## eos_token을 시퀀스 마지막에 추가하며 attention_mask의 마지막에 1을 추가한다.\n",
    "    if(result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "       and len(result[\"input_ids\"]) < max_seq_len\n",
    "       and add_eos_token):\n",
    "        result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "        result[\"attention_mask\"].append(1)\n",
    "\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(data_point, train_on_inputs, max_seq_len, add_eos_token):\n",
    "    ## 원천 데이터를 알파카 프롬프트로 변환.\n",
    "    full_prompt = generate_prompt(data_point[\"instruction\"], data_point[\"input\"], data_point[\"output\"])\n",
    "\n",
    "    ## 토크나이징.\n",
    "    tokenized_full_prompt = tokenize(full_prompt, max_seq_len, add_eos_token)\n",
    "    \n",
    "    ## train_on_inputs == False인 경우 input에서는 손실이 계산되지 않게 함.\n",
    "    ## train_on_inputs == True인 경우 input에서도 손실이 계산(학습)이 되는데 연산량은 증가하지만 성능이 더 좋다는 연구가 있음.\n",
    "    if not train_on_inputs:\n",
    "        user_prompt = generate_prompt(data_point[\"instruction\"], data_point[\"input\"])\n",
    "        \n",
    "        ## eos 토큰을 추가하지 않게 함.(토큰 하나를 줄이기 위함)\n",
    "        tokenized_user_prompt = tokenize(user_prompt, add_eos_token=add_eos_token)\n",
    "\n",
    "        user_prompt_len = len(tokenized_user_prompt[\"input_ids\"])\n",
    "\n",
    "        if add_eos_token:\n",
    "            user_prompt_len -= 1\n",
    "\n",
    "        ## 질문에 해당하는 부분에는 -100을 곱하게 되어 학습을 하지 않게 하고, 정답 부분에서만 손실이 발생되도록 만든다.\n",
    "        tokenized_full_prompt[\"labels\"] = [-100] * user_prompt_len + tokenized_full_prompt[\"labels\"][user_prompt_len:]\n",
    "\n",
    "    return tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a974e99de9842ba8cef8eacfa3ceeef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49371 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363c50eb4831436aafaf6d8b4ee34d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/249 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if val_size > 0:\n",
    "    train_val = dataset[\"train\"].train_test_split(\n",
    "        test_size=val_size, \n",
    "        shuffle=True, \n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    train_data = (\n",
    "        train_val[\"train\"]\n",
    "        .shuffle()\n",
    "        .map(lambda x: generate_and_tokenize_prompt(\n",
    "            x, \n",
    "            train_on_inputs=train_on_inputs, \n",
    "            max_seq_len=max_seq_len,\n",
    "            add_eos_token=add_eos_token\n",
    "        ))\n",
    "    )\n",
    "    \n",
    "    val_data = (\n",
    "        train_val[\"test\"]\n",
    "        .shuffle()\n",
    "        .map(lambda x: generate_and_tokenize_prompt(\n",
    "            x, \n",
    "            train_on_inputs=train_on_inputs, \n",
    "            max_seq_len=max_seq_len,\n",
    "            add_eos_token=add_eos_token\n",
    "        ))\n",
    "    )\n",
    "else:\n",
    "    train_data = (\n",
    "        dataset[\"train\"]\n",
    "        .shuffle()\n",
    "        .map(lambda x: generate_and_tokenize_prompt(\n",
    "            x, \n",
    "            train_on_inputs=train_on_inputs, \n",
    "            max_seq_len=max_seq_len,\n",
    "            add_eos_token=add_eos_token\n",
    "        ))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sequence_lengths(dataset, tokenizer, template):\n",
    "    lengths = []\n",
    "    \n",
    "    for item in dataset['train']:\n",
    "        # Generate full prompt\n",
    "        if item.get('input'):\n",
    "            prompt = template[\"prompt_input\"].format(\n",
    "                instruction=item['instruction'], \n",
    "                input=item['input']\n",
    "            ) + item['output']\n",
    "        else:\n",
    "            prompt = template[\"prompt_no_input\"].format(\n",
    "                instruction=item['instruction']\n",
    "            ) + item['output']\n",
    "            \n",
    "        # Tokenize and get length\n",
    "        tokens = tokenizer(prompt, truncation=False)\n",
    "        lengths.append(len(tokens['input_ids']))\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        'mean': np.mean(lengths),\n",
    "        'median': np.median(lengths),\n",
    "        'p95': np.percentile(lengths, 95),\n",
    "        'p99': np.percentile(lengths, 99),\n",
    "        'max': np.max(lengths),\n",
    "        'min': np.min(lengths)\n",
    "    }\n",
    "    \n",
    "    return stats, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Length Statistics:\n",
      "Mean: 107.52\n",
      "Median: 101.00\n",
      "95th percentile: 175.00\n",
      "99th percentile: 236.00\n",
      "Max: 797\n",
      "Min: 39\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 분석 실행\n",
    "stats, lengths = analyze_sequence_lengths(dataset, tokenizer, template)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Sequence Length Statistics:\")\n",
    "print(f\"Mean: {stats['mean']:.2f}\")\n",
    "print(f\"Median: {stats['median']:.2f}\")\n",
    "print(f\"95th percentile: {stats['p95']:.2f}\")\n",
    "print(f\"99th percentile: {stats['p99']:.2f}\")\n",
    "print(f\"Max: {stats['max']}\")\n",
    "print(f\"Min: {stats['min']}\")\n",
    "\n",
    "# 히스토그램 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(lengths, bins=50)\n",
    "plt.title('Distribution of Sequence Lengths')\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(stats['p95'], color='r', linestyle='--', label='95th percentile')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, ## 모델 파라미터를 NF4로 양자화.\n",
    "    bnb_4bit_use_double_quant=True, ## 양자화 단계에서 발생하는 상수(scaling factor)도 양자화.\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, ## 연산 단계에서는 bf16으로 dequantize.\n",
    "    bnb_4bit_quant_storage=torch.bfloat16, ## 양자화된 가중치를 저장할 때 사용할 데이터 타입.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pervinco/miniconda3/envs/nlp-project/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e673e852e9294059b34692764cc53781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config = quantization_config,\n",
    "    torch_dtype = torch.bfloat16,\n",
    "    device_map = {\"\" : 0}\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model) ## 모델 양자화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable targer module: ['k_proj', 'gate_proj', 'o_proj', 'q_proj', 'down_proj', 'v_proj', 'up_proj']\n"
     ]
    }
   ],
   "source": [
    "## adapter를 추가할 선형 모듈들이 무엇이 있는지 탐색.\n",
    "def find_all_linear_names(model):\n",
    "  cls = bnb.nn.Linear4bit\n",
    "  lora_module_names = set()\n",
    "  for name, module in model.named_modules():\n",
    "    if isinstance(module, cls):\n",
    "      names = name.split('.')\n",
    "      lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "  return list(lora_module_names)\n",
    "\n",
    "print('Trainable targer module:',find_all_linear_names(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): LlamaForCausalLM(\n",
      "      (model): LlamaModel(\n",
      "        (embed_tokens): Embedding(128256, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x LlamaDecoderLayer(\n",
      "            (self_attn): LlamaSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): LlamaRMSNorm()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 13631488 || all params: 4554231808 || trainable%: 0.29931475986915773\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameter setting\n",
    "output_dir=f\"{model_id.replace('/', '_')}-{data_id.replace('/', '_')}-QLoRA\"\n",
    "\n",
    "num_epochs = 1\n",
    "train_batch_size = 4\n",
    "valid_batch_size = 1\n",
    "gradient_accumulation_steps = 16\n",
    "warmup_steps = 10\n",
    "learning_rate = 5e-7\n",
    "group_by_length = False\n",
    "optimizer = 'paged_adamw_8bit'\n",
    "\n",
    "# adam 활용시\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "lr_scheduler = 'cosine'\n",
    "logging_steps = 1\n",
    "\n",
    "use_wandb = True\n",
    "wandb_run_name = 'Single_GPU_Optim'\n",
    "\n",
    "use_fp16 = False\n",
    "use_bf_16 = True\n",
    "evaluation_strategy = 'steps'\n",
    "eval_steps = 50\n",
    "save_steps = 50\n",
    "save_strategy = 'steps'\n",
    "\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    args=TrainingArguments(per_device_train_batch_size=train_batch_size,\n",
    "                           per_device_eval_batch_size=valid_batch_size,\n",
    "                           gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "                           warmup_steps=warmup_steps,\n",
    "                           num_train_epochs=num_epochs,\n",
    "                           learning_rate=learning_rate,\n",
    "                           adam_beta1=beta1,\n",
    "                           adam_beta2=beta2,\n",
    "                           fp16=use_fp16,\n",
    "                           bf16=use_bf_16,\n",
    "                           logging_steps=logging_steps,\n",
    "                           optim=optimizer,\n",
    "                           evaluation_strategy=evaluation_strategy if val_size > 0 else \"no\",\n",
    "                           save_strategy=\"steps\",  #스텝기준으로 save\n",
    "                           eval_steps=eval_steps if val_size > 0 else None,\n",
    "                           save_steps=save_steps,\n",
    "                           lr_scheduler_type=lr_scheduler,\n",
    "                           output_dir=output_dir,\n",
    "                           #save_total_limit = 4,\n",
    "                           load_best_model_at_end=True if val_size > 0 else False ,\n",
    "                           group_by_length=group_by_length,\n",
    "                           report_to=\"wandb\" if use_wandb else None,\n",
    "                           run_name=wandb_run_name if use_wandb else None),\n",
    "\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, \n",
    "                                         pad_to_multiple_of=8, ## 패딩할 길이를 8의 배수로 맞춤(GPU 연산 최적화를 위해 시퀀스 길이를 8의 배수로 맞춤)\n",
    "                                         return_tensors=\"pt\", \n",
    "                                         padding=True), ## 배치 내 시퀀스들을 동일한 길이로 패딩\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzfbtldnz\u001b[0m (\u001b[33mpervin0527\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pervinco/LLM-tutorials/custom/wandb/run-20241127_222433-59g4faw4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pervin0527/huggingface/runs/59g4faw4' target=\"_blank\">Single_GPU_Optim</a></strong> to <a href='https://wandb.ai/pervin0527/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pervin0527/huggingface' target=\"_blank\">https://wandb.ai/pervin0527/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pervin0527/huggingface/runs/59g4faw4' target=\"_blank\">https://wandb.ai/pervin0527/huggingface/runs/59g4faw4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/pervinco/miniconda3/envs/nlp-project/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/pervinco/miniconda3/envs/nlp-project/lib/python3.9/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='771' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 28/771 03:35 < 1:42:30, 0.12 it/s, Epoch 0.03/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer가 저장하는 것은 전체 모델 + 어뎁터가 아니라 어뎁터만 저장하는 것이기 때문에 별도로 base_model과 학습된 어뎁터를 병합하는 과정이 필요하다.\n",
    "\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_id, token=hf_token)\n",
    "\n",
    "merged_model = PeftModel.from_pretrained(base_model, output_dir)\n",
    "merged_model = merged_model.merge_and_unload()\n",
    "\n",
    "merged_model.push_to_hub(f\"pervin0527/{output_dir}\")\n",
    "tokenizer.push_to_hub(f\"pervin0527/{output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"\n",
    "    학습된 모델과 토크나이저를 로드하는 함수\n",
    "    \"\"\"\n",
    "    # 토크나이저 로드\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    \n",
    "    # 모델 설정 로드\n",
    "    config = PeftConfig.from_pretrained(model_path)\n",
    "    \n",
    "    # 기본 모델 로드\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        config.base_model_name_or_path,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # LoRA 모델 로드\n",
    "    model = PeftModel.from_pretrained(base_model, model_path)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "def generate_response(instruction, input_text=None, model=None, tokenizer=None, max_length=256):\n",
    "    \"\"\"\n",
    "    주어진 instruction과 input에 대한 응답을 생성하는 함수\n",
    "    \"\"\"\n",
    "    # 프롬프트 템플릿\n",
    "    if input_text:\n",
    "        prompt = f\"아래는 문제를 설명하는 지시사항과 구체적인 답변 방식을 요구하는 입력이 함께 있는 문장입니다. 이 요청에 대해 적절하게 답변해주세요.\\n###입력:{input_text}\\n###지시사항:{instruction}\\n###답변:\"\n",
    "    else:\n",
    "        prompt = f\"아래는 문제를 설명하는 지시사항입니다. 이 요청에 대해 적절하게 답변해주세요.\\n###지시사항:{instruction}\\n###답변:\"\n",
    "    \n",
    "    # 입력 인코딩\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    # 생성 파라미터 설정\n",
    "    generation_config = {\n",
    "        \"max_new_tokens\": max_length,\n",
    "        \"do_sample\": True,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9,\n",
    "        \"repetition_penalty\": 1.1,\n",
    "        \"num_return_sequences\": 1,\n",
    "        \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    }\n",
    "    \n",
    "    # 텍스트 생성\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, **generation_config)\n",
    "    \n",
    "    # 디코딩 및 응답 추출\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = full_response.split(\"###답변:\")[-1].strip()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 경로 설정\n",
    "model_path = \"pervin0527/beomi_Llama-3-Open-Ko-8B-Bingsu_ko_alpaca_data-QLoRA\"  # 실제 모델 경로로 수정 필요\n",
    "\n",
    "# 모델 및 토크나이저 로드\n",
    "print(\"모델을 로딩중입니다...\")\n",
    "model, tokenizer = load_model(model_path)\n",
    "print(\"모델 로딩이 완료되었습니다.\")\n",
    "\n",
    "# 대화형 인터페이스\n",
    "print(\"\\n종료하려면 'quit' 또는 'exit'를 입력하세요.\")\n",
    "while True:\n",
    "    # 사용자 입력 받기\n",
    "    instruction = input(\"\\n지시사항을 입력하세요: \")\n",
    "    if instruction.lower() in ['quit', 'exit']:\n",
    "        break\n",
    "        \n",
    "    input_text = input(\"입력(선택사항, 없으면 엔터): \")\n",
    "    if not input_text:\n",
    "        input_text = None\n",
    "        \n",
    "    # 응답 생성\n",
    "    print(\"\\n응답을 생성중입니다...\")\n",
    "    response = generate_response(instruction, input_text, model, tokenizer)\n",
    "    print(f\"\\n응답: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
