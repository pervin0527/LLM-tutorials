{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "from uuid import uuid4\n",
    "from pymongo import MongoClient\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"./keys.env\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "\n",
    "MONGO_DB_URL = os.getenv(\"MONGO_DB_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = LANGSMITH_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_name = \"intfloat/multilingual-e5-large-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB에서 데이터 꺼내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_mongo(db_name, collection_name):\n",
    "    \"\"\"MongoDB 연결\"\"\"\n",
    "    try:\n",
    "        client = MongoClient(MONGO_DB_URL)\n",
    "        db = client[db_name]\n",
    "        collection = db[collection_name]\n",
    "        # logger.info(f\"✅ {db_name} - {collection_name} 연결 성공\")\n",
    "        return collection\n",
    "    \n",
    "    except Exception as e:\n",
    "        # logger.error(f\"❌ {db_name} - {collection_name} 연결 실패: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_collection = connect_to_mongo(\"culture_db\", \"company\")\n",
    "# hompage_collection = connect_to_mongo(\"culture_db\", \"company_homepage\")\n",
    "\n",
    "# # 기업 데이터 가져오기\n",
    "# print(\"기업 데이터 불러오는 중...\")\n",
    "# companies = company_collection.find()\n",
    "# total_data = []\n",
    "# for company in companies:\n",
    "#     id = company[\"_id\"]\n",
    "#     name = company[\"company_name\"]\n",
    "#     biz_no = company[\"biz_no\"]\n",
    "#     total_data.append((id, name, biz_no))\n",
    "\n",
    "# print(f\"총 {len(total_data)}개 기업 데이터를 불러왔습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 길이 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_results = analyze_document_lengths(total_data, hompage_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_results = analyze_token_lengths(total_data, hompage_collection, embed_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n분석이 완료되었습니다.\")\n",
    "# print(f\"분석 결과는 'analysis_results' 디렉토리에 저장되었습니다.\")\n",
    "\n",
    "# # 요약 정보 출력\n",
    "# print(\"\\n=== 문서 길이 분석 요약 ===\")\n",
    "# print(f\"총 문서 수: {doc_results['total_stats']['total_documents']}\")\n",
    "# print(f\"평균 문서 길이: {doc_results['total_stats']['avg_length']:.1f} 글자\")\n",
    "# print(f\"중앙값 문서 길이: {doc_results['total_stats']['median_length']:.1f} 글자\")\n",
    "# print(f\"최소 문서 길이: {doc_results['total_stats']['min_length']} 글자\")\n",
    "# print(f\"최대 문서 길이: {doc_results['total_stats']['max_length']} 글자\")\n",
    "\n",
    "# print(\"\\n=== 토큰 길이 분석 요약 ===\")\n",
    "# print(f\"모델: {embed_model_name}\")\n",
    "# print(f\"평균 토큰 길이: {token_results['total_token_stats']['avg_token_length']:.1f} 토큰\")\n",
    "# print(f\"중앙값 토큰 길이: {token_results['total_token_stats']['median_token_length']:.1f} 토큰\")\n",
    "# print(f\"최소 토큰 길이: {token_results['total_token_stats']['min_token_length']} 토큰\")\n",
    "# print(f\"최대 토큰 길이: {token_results['total_token_stats']['max_token_length']} 토큰\")\n",
    "# print(f\"평균 토큰/문자 비율: {token_results['correlation_data']['token_to_char_ratio'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homepage_collection = connect_to_mongo(\"culture_db\", \"company_homepage\")\n",
    "# total_pages = []\n",
    "# for id, name, biz_no in total_data:\n",
    "#     id = convert_objectid_to_str(id)\n",
    "#     print(f\"{id}, {name} {biz_no}\")\n",
    "#     homepage = homepage_collection.find_one({\"company_id\": id})\n",
    "\n",
    "#     if homepage is None:\n",
    "#         print(f\"Warning: No homepage data found for {name}\")\n",
    "#         continue\n",
    "\n",
    "#     pages = homepage[\"pages\"]\n",
    "#     print(f\"{name} : {len(pages)}\")\n",
    "#     for page in homepage[\"pages\"]:\n",
    "#         total_pages.append((name, page))\n",
    "\n",
    "# print(len(total_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_docs = []\n",
    "# for company_name, page in total_pages:\n",
    "#     doc_id = str(uuid4())\n",
    "#     total_docs.append(\n",
    "#         Document(\n",
    "#             page_content=page[\"text\"], \n",
    "#             metadata={\n",
    "#                 \"company_name\": company_name, \n",
    "#                 \"url\": page[\"url\"],\n",
    "#                 \"original_doc_id\": doc_id\n",
    "#             }, \n",
    "#         id=doc_id)\n",
    "#     )\n",
    "\n",
    "# print(len(total_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homepage_collection = connect_to_mongo(\"culture_db\", \"company_homepage\")\n",
    "total_data = homepage_collection.find()\n",
    "\n",
    "total_docs = []\n",
    "for data in total_data:\n",
    "    pages = data['pages']\n",
    "    \n",
    "    for page in pages:\n",
    "        doc_id = str(uuid4())\n",
    "        total_docs.append(\n",
    "            Document(\n",
    "                page_content=page[\"text\"],\n",
    "                metadata={\n",
    "                    \"company_name\": data[\"company_name\"], \n",
    "                    \"url\": page[\"url\"], \n",
    "                    \"original_doc_id\": doc_id\n",
    "                },\n",
    "                id=doc_id\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(len(total_docs))\n",
    "\n",
    "sample = total_docs[0]\n",
    "print(f\"{sample.metadata['company_name']} : {sample.metadata['url']}\\n{sample.page_content[:100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문자열 청킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \"],\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=250,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(total_docs)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sample_idx = random.randint(0, len(total_docs))\n",
    "print(sample_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_docs_by_id = {}\n",
    "for doc in total_docs:\n",
    "    original_docs_by_id[doc.metadata['original_doc_id']] = doc\n",
    "\n",
    "# 청크에서 원본 문서 찾기 함수\n",
    "def find_original_document(chunk):\n",
    "    \"\"\"청크에서 원본 문서 찾기\"\"\"\n",
    "    if 'original_doc_id' in chunk.metadata:\n",
    "        original_id = chunk.metadata['original_doc_id']\n",
    "        return original_docs_by_id.get(original_id)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_chunk = chunks[sample_idx]\n",
    "print(\"=\" * 50, \"chunk\", \"=\" * 50)\n",
    "print(sample_chunk.metadata['original_doc_id'])\n",
    "print(sample_chunk.metadata['company_name'], sample_chunk.metadata['url'])\n",
    "print(\"=\" * 100)\n",
    "print(len(sample_chunk.page_content))\n",
    "print(sample_chunk.page_content[:100])\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"=\" * 50, \"original_doc\", \"=\" * 50)\n",
    "original_doc = find_original_document(sample_chunk)\n",
    "print(original_doc.metadata['company_name'], original_doc.metadata['url'])\n",
    "print(\"=\" * 100)\n",
    "print(len(original_doc.page_content))\n",
    "print(original_doc.page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰 청킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# def hf_tokenizer_len(text):\n",
    "#     # 원하는 모델에 맞는 토크나이저 선택 (예: BERT, RoBERTa 등)\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(embed_model_name)\n",
    "#     tokens = tokenizer.encode(text)\n",
    "#     return len(tokens)\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "#     chunk_size=900,\n",
    "#     chunk_overlap=150,\n",
    "#     length_function=hf_tokenizer_len  # 토큰 길이 계산 함수\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_chunks = text_splitter.split_documents(total_docs)\n",
    "# print(len(token_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_experimental.text_splitter import SemanticChunker\n",
    "# from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(\n",
    "#     model_name=embed_model_name,\n",
    "#     model_kwargs=cfg[\"model_kwargs\"],\n",
    "#     encode_kwargs=cfg[\"encode_kwargs\"]\n",
    "# )\n",
    "\n",
    "# semantic_splitter = SemanticChunker(\n",
    "#     embeddings=embeddings,\n",
    "#     breakpoint_threshold_type=\"percentile\",\n",
    "#     breakpoint_threshold_amount=70,\n",
    "# )\n",
    "\n",
    "# # 시맨틱 청킹 적용\n",
    "# semantic_chunks = semantic_splitter.split_documents(total_docs)\n",
    "# print(f\"시맨틱 청킹 후 청크 개수: {len(semantic_chunks)}\")\n",
    "\n",
    "# # 샘플 시맨틱 청크 확인\n",
    "# sample_semantic_idx = random.randint(0, len(semantic_chunks) - 1)\n",
    "# sample_semantic_chunk = semantic_chunks[sample_semantic_idx]\n",
    "# print(f\"샘플 시맨틱 청크 {sample_semantic_idx}:\")\n",
    "# print(\"=\" * 100)\n",
    "# print(f\"회사명: {sample_semantic_chunk.metadata['company_name']}\")\n",
    "# print(f\"URL: {sample_semantic_chunk.metadata['url']}\")\n",
    "# print(f\"길이: {len(sample_semantic_chunk.page_content)} 글자\")\n",
    "# print(\"=\" * 100)\n",
    "# print(sample_semantic_chunk.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "# embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "# embedding_model = UpstageEmbeddings(model=\"upstage-e5-large\")\n",
    "\n",
    "model_kwargs = {\n",
    "    \"device\": \"cuda:1\",\n",
    "    \"trust_remote_code\": True\n",
    "}\n",
    "encode_kwargs = {\n",
    "    \"normalize_embeddings\": True,\n",
    "    \"batch_size\": 128,\n",
    "    \"multi_process\": True,\n",
    "    \"show_progress\": True\n",
    "}\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=embed_model_name, \n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "벡터 저장소에 만들어질 index 타입을 설정.\n",
    " - IP : 내적을 기반으로 코사인 유사도 계산으로 쿼리 벡터와 벡터 저장소 내 모든 벡터를 비교하여 가장 유사한 벡터를 찾는다.\n",
    " - L2 : 유클리드 거리를 기반으로 유사도 계산으로 쿼리 벡터와 벡터 저장소 내 모든 벡터를 비교하여 가장 유사한 벡터를 찾는다.\n",
    " - HNSW : 비정형 데이터에 적합한 효율적인 검색을 위한 인덱스 타입으로 모든 벡터를 비교하지 않고 적절한 후보 벡터를 찾아 비교하여 가장 유사한 벡터를 찾는다.\n",
    "\"\"\"\n",
    "\n",
    "sample_chunk = chunks[sample_idx].page_content\n",
    "index = faiss.IndexFlatIP(len(embedding_model.embed_query(sample_chunk)))\n",
    "## index = faiss.IndexFlatL2(len(embedding_model.embed_query(sample_text)))\n",
    "## index = faiss.IndexHNSWFlat(len(embedding_model.embed_query(sample_text)), 32)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embedding_model,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    "    # normalize_L2=True\n",
    ")\n",
    "\n",
    "vector_store.add_documents(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "save_path = f\"./indexes/{now}\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "vector_store.save_local(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_results = vector_store.similarity_search_with_score(\"코리아교육그룹의 비전, 목표\") ## 쿼리에 대한 검색 수행\n",
    "\n",
    "for document, score in ret_results:\n",
    "    print(document.metadata['company_name'], document.metadata['url'], score) ## 회사명, 홈페이지 주소, 유사도 점수\n",
    "    print(\"=\" * 100)\n",
    "    print(document.page_content[:50]) ## 본문 내용\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_results = vector_store.similarity_search_with_relevance_scores(\"코리아교육그룹의 비전, 목표\") ## 쿼리에 대한 검색 수행\n",
    "\n",
    "for document, score in ret_results:\n",
    "    print(document.metadata['company_name'], document.metadata['url'], score) ## 회사명, 홈페이지 주소, 유사도 점수\n",
    "    print(\"=\" * 100)\n",
    "    print(document.page_content[:50]) ## 본문 내용\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    앱의 상태를 정의. 질문, 검색된 문서, 생성된 답변으로 구성되어 있다.\n",
    "    \"\"\"\n",
    "    context: List[Document]\n",
    "    question: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=OPENAI_API_KEY)\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search_with_relevance_scores(state[\"question\"])\n",
    "    return {\"context\" : retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    \"\"\"\n",
    "    검색된 문서와 질문을 받아 답변을 생성하는 함수.\n",
    "    \"\"\"\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc, _ in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "## 그래프를 정의하고 노드들을 시퀀스로 추가.\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "\n",
    "## 검색 노드에서 생성 노드로 연결.\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"retrieve\", retrieve)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph_builder.add_edge(\"retrieve\", \"generate\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"question\": \"코리아교육그룹의 비전, 목표는 무엇인가?\"})\n",
    "print(f\"검색된 문서 :\\n {result['context']}\\n\\n\")\n",
    "print(f\"생성된 답변 :\\n {result['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
