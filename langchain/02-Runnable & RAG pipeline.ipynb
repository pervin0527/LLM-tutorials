{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"./keys.env\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = LANGSMITH_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
    "index_path = \"./indexes/2025-04-10-01-02-18\"\n",
    "\n",
    "\n",
    "model_kwargs = {\n",
    "    \"device\": \"cuda:1\",\n",
    "    \"trust_remote_code\": True\n",
    "}\n",
    "encode_kwargs = {\n",
    "    \"normalize_embeddings\": True,\n",
    "    \"batch_size\": 128,\n",
    "    \"multi_process\": True,\n",
    "    \"show_progress\": True\n",
    "}\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=embed_model_name, \n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "vector_store = FAISS.load_local(index_path, embeddings=embedding_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "reference : https://wikidocs.net/234016 \n",
    "\n",
    "vectore_store에 대한 검색기(retriever)를 생성.\n",
    " - search_type : 검색 유형. similarity, mmr(Maximal Marginal Relevance), similarity_score_threshold 중 1개\n",
    " - search_kwargs : 추가 검색 옵션\n",
    "    - k : 반환할 문서 수(기본=4)\n",
    "    - score_threshold : 유사도 임계치(기본=0.0)\n",
    "    - fetch_k : MMR 알고리즘에 전달할 문서 수(기본=20)\n",
    "    - lambda_mult : MMR 결과의 다양성을 조절.(0~1사이 값으로 기본값=0.5)\n",
    "    - filter : 문서 메타데이터 기반 필터링 --> 메타데이터 필터링으로 특정 조건의 문서만 검색 가능.\n",
    "\"\"\"\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 10, \"score_threshold\": 0.3}\n",
    ")\n",
    "\n",
    "ret_results = retriever.invoke(\"코리아교육그룹의 비전, 미래, 목표\")\n",
    "\n",
    "for ret in ret_results:\n",
    "    print(ret.metadata['company_name'], ret.metadata['url'], ret.metadata['original_doc_id'])\n",
    "    print(\"=\"*100)\n",
    "    print(ret.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_or_respond(state:MessagesState):\n",
    "    \"\"\"검색 툴을 호출하거나 직접 응답을 생성\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tools = ToolNode([retrieve])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def generate(state:MessagesState):\n",
    "    \"\"\"응답을 생성하는 노드\"\"\"\n",
    "    print(\"\\n===== state['messages'] 내용 출력 =====\")\n",
    "    for i, msg in enumerate(state[\"messages\"]):\n",
    "        print(f\"[{i}] type: {msg.type}, content: {msg.content}\")\n",
    "    print(\"====================================\\n\")\n",
    "\n",
    "    recent_tool_messages = [] ## 생성된 ToolMessage를 저장할 리스트\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1] ## 역순으로 정렬\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages) ## 검색된 문서들을 프롬프트에 반영할 수 있도록 문자열로 변환\n",
    "\n",
    "    ## 시스템 프롬프트\n",
    "    system_message_content = (\n",
    "        \"당신은 주어진 질문에 대해 정확한 답변을 제공하는 전문가입니다.\"\n",
    "        \"다음은 주어진 질문과 검색된 컨텍스트입니다.\"\n",
    "        \"이 컨텍스트를 사용하여 질문에 대한 정확한 답변을 제공하세요.\"\n",
    "        \"만약 답변을 알 수 없다면, '알 수 없습니다'라고 답변하세요.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "\n",
    "    ## 대화 메시지 추출\n",
    "    conversation_messages = []\n",
    "    for message in state[\"messages\"]:\n",
    "        ## 사용자나 시스템 메세지 포함\n",
    "        if message.type in (\"human\", \"system\"):\n",
    "            conversation_messages.append(message)\n",
    "        \n",
    "        ## AI 메세지이고 툴 호출이 없는 경우 포함\n",
    "        elif message.type == \"ai\" and not message.tool_calls:\n",
    "            conversation_messages.append(message)\n",
    "    \n",
    "    ## 시스템 메시지와 대화 메시지 결합\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\"query_or_respond\", tools_condition, {END:END, \"tools\":\"tools\"})\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"안녕하세요\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"코리아교육그룹의 비전, 목표, 미래에 대한 내용들을 추출하고 정리해서 문장형태로 서술해주세요.\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "config = {\"configurable\" : {\"thread_id\" : \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"코리아교육그룹의 비전, 목표, 미래에 대한 내용들을 추출하고 정리해서 문장형태로 서술해주세요.\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"코리아교육그룹의 기업문화, 업무스타일에 대해 알려줘\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "config = {\"configurable\" : {\"thread_id\" : \"abc123\"}}\n",
    "\n",
    "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)\n",
    "\n",
    "display(Image(agent_executor.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = (\n",
    "    \"코리아교육그룹의 비전, 목표, 미래에 대한 내용들을 추출하고 정리해서 문장형태로 서술해주세요.\\n\\n\"\n",
    "    \"서술된 내용을 바탕으로 코리아교육그룹이 비전을 이루기 위해 어떤 노력을 하는지, 어떤 문화를 만들었는지 설명해줘.\"\n",
    ")\n",
    "\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"주어진 기업이 설정한 비전, 목표, 미래에 대한 내용들을 추출하고 정리해서 문장형태로 서술해주세요.\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"user\", \"{input_documents}\")\n",
    "])\n",
    "\n",
    "str_ret_results = [ret.page_content for ret in ret_results]\n",
    "prompt = prompt_template.invoke({\"input_documents\": str_ret_results})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "chat_model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0, api_key=ANTHROPIC_API_KEY)\n",
    "response = chat_model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "company_name = \"LG CNS\"\n",
    "\n",
    "# 1. 시스템 프롬프트 템플릿 정의\n",
    "system_template = \"주어진 기업이 설정한 비전, 목표, 미래에 대한 내용들을 추출하고 정리해서 문장형태로 서술해주세요.\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"user\", \"{input_documents}\")\n",
    "])\n",
    "\n",
    "# 2. 벡터 저장소 → retriever (Runnable)\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 10, \"score_threshold\": 0.3}\n",
    ")\n",
    "\n",
    "# 3. 검색 결과에서 page_content만 추출하는 함수 (Runnable로 래핑)\n",
    "extract_content = RunnableLambda(lambda docs: {\"input_documents\": [doc.page_content for doc in docs]})\n",
    "\n",
    "# 4. LLM 모델\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0, api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "# 5. 체인 구성: retriever → page_content 추출 → prompt → llm\n",
    "chain = retriever | extract_content | prompt_template | llm\n",
    "\n",
    "# 6. 실행\n",
    "response = chain.invoke(f\"{company_name}의 비전, 미래, 목표\")\n",
    "print(f\"{company_name}에 대한 응답:\\n{response.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
