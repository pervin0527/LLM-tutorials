{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n",
      "    num_rows: 17554\n",
      "})\n",
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "klue_mrc_dataset = load_dataset('klue', 'mrc', split='train')\n",
    "sentence_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "print(klue_mrc_dataset)\n",
    "print(sentence_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n",
      "        num_rows: 16554\n",
      "    })\n",
      "})\n",
      "(1000, 768)\n"
     ]
    }
   ],
   "source": [
    "klue_mrc_dataset = klue_mrc_dataset.train_test_split(train_size=1000, shuffle=False)\n",
    "print(klue_mrc_dataset)\n",
    "\n",
    "klue_mrc_dataset = klue_mrc_dataset['train']\n",
    "\n",
    "embeddings = sentence_model.encode(klue_mrc_dataset['context'])\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[300.91888 420.86273 420.86273]]\n",
      "[[  0 920 921]]\n"
     ]
    }
   ],
   "source": [
    "query = \"이번 연도에는 언제 비가 많이 올까?\"\n",
    "query_embedding = sentence_model.encode([query])\n",
    "\n",
    "distances, indices = index.search(query_embedding, 3)\n",
    "print(distances)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2~3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다.장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20~21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24~25일이었으며 장마기간은 32일, 강수일수는 17.2일이었다.기상청은 올해 장마기간의 평균 강수량이 350~400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다.\n",
      "연구 결과에 따르면, 오리너구리의 눈은 대부분의 포유류보다는 어류인 칠성장어나 먹장어, 그 중에서도 태평양먹장어(Eptatretus stoutii)와 구조가 비슷하다. 게다가 오리너구리의 눈에서는 같은 포유류에게서 찾아보기 힘든 이중 원추세포가 발견된다. \n",
      "\n",
      "크게 발달하지도 않았고 물 속에서도 시야 확보를 위하여 쓰이지 않는 눈이지만, 오리너구리의 조상뻘 되는 종들이 한때 시각에 보다 크게 의존했다는 증거는 많이 남아 있다. 오리너구리의 눈 구조를 살펴보면 수정체와 그와 접하는 각막 표면은 평평한 데 비해 안구 쪽을 향하는 수정체 표면은 볼록한데, 이것은 수달 및 바다사자 등 수서성 포유류의 눈에서 알 수 있는 대표적인 특징이다.\n",
      "\n",
      "관자뼈 쪽에는 망막신경절세포가 집중되어 있는데, 이는 시야를 대폭 넓혀 양안시(兩眼視) 동물이 사냥 및 포식 행위를 하는 데 중요한 역할을 한다. 이와 같은 특질을 통해 오리너구리가 물 속에서의 시각을 도태시킨 대신 전기수용 체계를 발달시켜 수중·야간 활동에 성공적으로 적응하여 진화했다는 것을 알 수 있다\n",
      "연구 결과에 따르면, 오리너구리의 눈은 대부분의 포유류보다는 어류인 칠성장어나 먹장어, 그 중에서도 태평양먹장어(Eptatretus stoutii)와 구조가 비슷하다. 게다가 오리너구리의 눈에서는 같은 포유류에게서 찾아보기 힘든 이중 원추세포가 발견된다. \n",
      "\n",
      "크게 발달하지도 않았고 물 속에서도 시야 확보를 위하여 쓰이지 않는 눈이지만, 오리너구리의 조상뻘 되는 종들이 한때 시각에 보다 크게 의존했다는 증거는 많이 남아 있다. 오리너구리의 눈 구조를 살펴보면 수정체와 그와 접하는 각막 표면은 평평한 데 비해 안구 쪽을 향하는 수정체 표면은 볼록한데, 이것은 수달 및 바다사자 등 수서성 포유류의 눈에서 알 수 있는 대표적인 특징이다.\n",
      "\n",
      "관자뼈 쪽에는 망막신경절세포가 집중되어 있는데, 이는 시야를 대폭 넓혀 양안시(兩眼視) 동물이 사냥 및 포식 행위를 하는 데 중요한 역할을 한다. 이와 같은 특질을 통해 오리너구리가 물 속에서의 시각을 도태시킨 대신 전기수용 체계를 발달시켜 수중·야간 활동에 성공적으로 적응하여 진화했다는 것을 알 수 있다\n"
     ]
    }
   ],
   "source": [
    "for idx in indices[0]:\n",
    "    print(klue_mrc_dataset['context'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가? \n",
      "\n",
      "==================================================\n",
      "78\n",
      "태평양 전쟁 중 뉴기니 방면에서 진공 작전을 실시해 온 더글러스 맥아더 장군을 사령관으로 하는 미 육군 주체의 연합군 남서 태평양 방면군은 1944년 후반 마침내 필리핀을 진공하기로 결정했다. 그 첫 단계로 필리핀 방면의 전략 거점의 확보가 필요하였으며, 뉴기니 서쪽에 위치한 말루쿠 제도의 모로타이 섬을 공격 목표로 정했다. 또한 동시에 팔라우 제도의 펠렐리우 섬과 앙가우르 섬에도 미국 해군 주도의 연합국 중부 태평양 방면군이 공략을 맡았다.(이때의 전략 결정의 경위에 대해서는 필리핀 전투 (1944 - 1945)#미국을 참조.)\n",
      "\n",
      "한편, 1942년에 네덜란드령 동인도의 일부였던 모로타이 섬을 점령한 일본군은 이후 수비 부대를 증강배치하지 않았다. 1944년 말루쿠 제도 방면의 방비 강화를 도모하고자 파견된 제32사단은 평야가 많은 비행장 건설에 적합한 주변의 할마헤라 섬을 방어의 중심으로 여겼다. 따라서 모로타이 섬에는 제32사단의 2개 대대가 비행장 건설을 추진했지만, 배수가 좋지 않아 건설을 포기했다. 이 2개 대대가 할마헤라 섬으로 철수한 이후에는 카와시마 타케노부(川島威伸) 중위를 지휘관으로 하는 제2유격대 소속의 2개 중대(주로 다카사고의용대)만 배치되어 있었다.\n",
      "\n",
      "연합군이 상륙했을 때, 섬에는 9000명의 현지인이 살고 있었다. 도민에 대한 선무공작을 수행하기 위해 연합군의 상륙 부대에는 네덜란드 군 민정반이 추가 되었다.\n",
      "==================================================\n",
      "79\n",
      "태평양 전쟁 중 뉴기니 방면에서 진공 작전을 실시해 온 더글러스 맥아더 장군을 사령관으로 하는 미 육군 주체의 연합군 남서 태평양 방면군은 1944년 후반 마침내 필리핀을 진공하기로 결정했다. 그 첫 단계로 필리핀 방면의 전략 거점의 확보가 필요하였으며, 뉴기니 서쪽에 위치한 말루쿠 제도의 모로타이 섬을 공격 목표로 정했다. 또한 동시에 팔라우 제도의 펠렐리우 섬과 앙가우르 섬에도 미국 해군 주도의 연합국 중부 태평양 방면군이 공략을 맡았다.(이때의 전략 결정의 경위에 대해서는 필리핀 전투 (1944 - 1945)#미국을 참조.)\n",
      "\n",
      "한편, 1942년에 네덜란드령 동인도의 일부였던 모로타이 섬을 점령한 일본군은 이후 수비 부대를 증강배치하지 않았다. 1944년 말루쿠 제도 방면의 방비 강화를 도모하고자 파견된 제32사단은 평야가 많은 비행장 건설에 적합한 주변의 할마헤라 섬을 방어의 중심으로 여겼다. 따라서 모로타이 섬에는 제32사단의 2개 대대가 비행장 건설을 추진했지만, 배수가 좋지 않아 건설을 포기했다. 이 2개 대대가 할마헤라 섬으로 철수한 이후에는 카와시마 타케노부(川島威伸) 중위를 지휘관으로 하는 제2유격대 소속의 2개 중대(주로 다카사고의용대)만 배치되어 있었다.\n",
      "\n",
      "연합군이 상륙했을 때, 섬에는 9000명의 현지인이 살고 있었다. 도민에 대한 선무공작을 수행하기 위해 연합군의 상륙 부대에는 네덜란드 군 민정반이 추가 되었다.\n",
      "==================================================\n",
      "3\n",
      "미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스터 대학교에서 핵물리학으로 박사 학위를 마쳤다. 제2차 세계대전중에 그는 매사추세츠 공과대학교 방사선 연구소에서 일하였다. 그곳에서 그는 레이다를 개발하였고, 딕 복사계와 마이크로파 수신기를 설계하였다. 그는 방사선 연구소의 지붕에서 이를 20K보다 낮은 우주 마이크로파 배경의 한계 온도를 설정하는 데 사용하였다.\n",
      "\n",
      "전후 1946년 그는 프린스턴 대학교로 돌아왔고, 이곳에서 자신의 경력의 나머지를 보내게 되었다. 그는 원자 물리학에서 레이저와 전자의 회전 자기 비율을 측정하는 것을 연구하였다. 그의 분광학과 발관 전송 분야의 중대한 기여는 딕 좁아짐(Dicke narrowing, 원자의 자유평균행로가 원자의 방사 전이의 한 파장의 길이보다 짧아지고, 광자의 흡수나 분출하는 동안에 원자의 속도와 방향은 많이 변하는 현상)이라 불리는 현상에 대한 예견이었다. 딕 좁아짐은 단파와 마이크로파 영역에서 상대적으로 낮은 압력에서 발생한다. 딕 좁아짐은 감마선에서 뫼스바우어 효과에 비견된다.\n",
      "\n",
      "그는 등가 원리를 이용한 일반 상대성 이론의 정확한 측정 프로그램의 개발에 그의 남은 경력을 보냈다. 칼 브랜스(Carl H. Brans)와 함께 그는 중력의 브랜스-딕 이론, 폴 디랙의 큰 수 가설과 마흐의 원리에 의해 영감을 얻은 일반 상대성 이론의 등가 원리의 깨짐을 발전시켰다. 하이라이트는 Roll과 Krotkov와 Dicke에 의한 등가 원리의 고전적인 측정이었고, 이 실험에서 이전의 작업들 보다 100배나 더 정확한 측정치를 얻었다. 디키는 또한 일반 상대성 이론의 고전적 시험 가운데 하나인, 수성의 근일점을 이해하는 데 유용한 태양 편평도를 측정하였다. 폴 디랙은 중력 상수가 우주의 거꾸로 나이와 부정확하게 일치하며, 중력 상수는 지금의 평형을 유지하기 위해 바뀌어야만 한다고 추측했다. 딕은 디랙의 관계가 선택 효과일 수 있다는 것을 깨달았다. 평형이 깨어졌을 다른 어떠한 시대에는 그 모순을 알아차릴 수 있는 지적인 생명채가 없을 것이다. 이것은 소위 약한 인간 중심 원리의 첫 번째 현대적 적용이다.\n"
     ]
    }
   ],
   "source": [
    "query = klue_mrc_dataset[3]['question']\n",
    "print(query, '\\n')\n",
    "\n",
    "query_embedding = sentence_model.encode([query])\n",
    "distances, indices = index.search(query_embedding, 3)\n",
    "\n",
    "for idx in indices[0]:\n",
    "    print(\"=\" * 50)\n",
    "    print(idx)\n",
    "    print(klue_mrc_dataset['context'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Document, VectorStoreIndex, ServiceContext, Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    }
   ],
   "source": [
    "# embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large-instruct\")\n",
    "# service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=None)\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large-instruct\")\n",
    "Settings.llm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = klue_mrc_dataset[:100]['context']\n",
    "documents = [Document(text=t) for t in text_list]\n",
    "\n",
    "index_llama = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "from transformers import PreTrainedTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25:\n",
    "    def __init__(self, corpus, tokenizer):\n",
    "        \"\"\"\n",
    "        tokenizer : 토크나이저\n",
    "        corpus : 문서 데이터셋\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.corpus = corpus\n",
    "\n",
    "        ## 각 문서를 토큰화\n",
    "        self.tokenized_corpus = self.tokenizer(corpus, add_special_tokens=False)['input_ids']\n",
    "        \n",
    "        ## 토큰화된 문서들의 수\n",
    "        self.n_docs = len(self.tokenized_corpus)\n",
    "\n",
    "        ## 전체 문서들의 평균 길이\n",
    "        self.avg_doc_lens = sum(len(lst) for lst in self.tokenized_corpus) / len(self.tokenized_corpus)\n",
    "\n",
    "        ## IDF 계산\n",
    "        self.idf = self.calculate_idf()\n",
    "\n",
    "        ## TF 계산\n",
    "        self.term_freqs = self.calculate_term_freqs()\n",
    "\n",
    "    def calculate_idf(self):\n",
    "        idf = defaultdict(float)\n",
    "        ## 토큰화된 문서들을 순회\n",
    "        for doc in self.tokenized_corpus:\n",
    "            ## 토큰화된 문서의 토큰들의 등장 횟수를 카운팅하고 딕셔너리에 저장.\n",
    "            for token_id in set(doc):\n",
    "                idf[token_id] += 1\n",
    "\n",
    "        for token_id, doc_frequency in idf.items():\n",
    "            idf[token_id] = math.log(((self.n_docs - doc_frequency + 0.5) / (doc_frequency + 0.5)) + 1)\n",
    "\n",
    "        return idf\n",
    "    \n",
    "    def calculate_term_freqs(self):\n",
    "        term_freqs = [defaultdict(int) for _ in range(self.n_docs)]\n",
    "        \n",
    "        ## 토큰화된 문서들을 순회\n",
    "        for i, doc in enumerate(self.tokenized_corpus):\n",
    "            for token_id in doc:\n",
    "                term_freqs[i][token_id] += 1\n",
    "\n",
    "        return term_freqs\n",
    "    \n",
    "    def get_scores(self, query, k1=1.2, b=0.75):\n",
    "        query = self.tokenizer([query], add_special_tokens=False)['input_ids'][0]\n",
    "        scores = np.zeros(self.n_docs)\n",
    "\n",
    "        for q in query:\n",
    "            idf = self.idf[q]\n",
    "            for i, term_freq in enumerate(self.term_freqs):\n",
    "                q_frequency = term_freq[q]\n",
    "                doc_len = len(self.tokenized_corpus[i])\n",
    "                score_q = idf * (q_frequency * (k1 + 1)) / ((q_frequency) + k1 * (1 - b + b * (doc_len / self.avg_doc_lens)))\n",
    "                scores[i] += score_q\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def get_top_k(self, query, k):\n",
    "        scores = self.get_scores(query)\n",
    "        top_k_indices = np.argsort(scores)[-k:][::-1]\n",
    "        top_k_scores = scores[top_k_indices]\n",
    "\n",
    "        return top_k_scores, top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44713859, 0.        , 0.52354835])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\n",
    "\n",
    "bm25 = BM25(['안녕하세요', '반갑습니다', '안녕 서울'], tokenizer)\n",
    "bm25.get_scores('안녕')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "갤럭시S5 언제 발매한다는 건지언제는 “27일 판매한다”고 했다가 “이르면 26일 판매한다\n",
      "베토벤의 후기는 1810-1819년에 시작되었다. 베토벤은 그의 청력 저하로 의기소침해 있\n",
      "도비는 감독이 되는 데 자신의 전망을 가졌다. 겨울 야구를 감독한 시즌 후에 그는 자신에게\n"
     ]
    }
   ],
   "source": [
    "bm25 = BM25(klue_mrc_dataset['context'], tokenizer)\n",
    "\n",
    "query = '아번 연도에는 언제 비가 많이 올까?'\n",
    "_, bm25_search_ranking = bm25.get_top_k(query, 100)\n",
    "\n",
    "for idx in bm25_search_ranking[:3]:\n",
    "    print(klue_mrc_dataset['context'][idx][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스\n",
      ";메카동(メカドン)\n",
      ":성우 : 나라하시 미키(ならはしみき)\n",
      "길가에 버려져 있던 낡은 느티나\n",
      ";메카동(メカドン)\n",
      ":성우 : 나라하시 미키(ならはしみき)\n",
      "길가에 버려져 있던 낡은 느티나\n"
     ]
    }
   ],
   "source": [
    "query = klue_mrc_dataset[3]['question']\n",
    "_, bm25_search_ranking = bm25.get_top_k(query, 100)\n",
    "\n",
    "for idx in bm25_search_ranking[:3]:\n",
    "    print(klue_mrc_dataset['context'][idx][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def reciprocal_rank_fusion(rankings, k=5):\n",
    "    rrf = defaultdict(float)\n",
    "    for ranking in rankings:\n",
    "        for i, doc_id in enumerate(ranking, 1):\n",
    "            rrf[doc_id] += 1.0 / (k + i)\n",
    "\n",
    "    return sorted(rrf.items(), key=lambda x : x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.30952380952380953),\n",
       " (3, 0.25),\n",
       " (4, 0.24285714285714285),\n",
       " (6, 0.2111111111111111),\n",
       " (2, 0.16666666666666666),\n",
       " (5, 0.1111111111111111)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings = [[1, 4, 3, 5, 6], [2, 1, 3, 6, 4]]\n",
    "reciprocal_rank_fusion(rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_vector_search(query, k):\n",
    "    query_embedding = sentence_model.encode([query])\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    \n",
    "    return distances[0], indices[0]\n",
    "\n",
    "def hybrid_search(query, k=20):\n",
    "    _, dense_search_ranking = dense_vector_search(query, 100)\n",
    "    _, bm25_search_ranking = bm25.get_top_k(query, 100)\n",
    "\n",
    "    results = reciprocal_rank_fusion([dense_search_ranking, bm25_search_ranking], k=k)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 쿼리 문장:  이번 연도에는 언제 비가 많이 올까?\n",
      "올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 \n",
      "갤럭시S5 언제 발매한다는 건지언제는 “27일 판매한다”고 했다가 “이르면 26일 판매한다\n",
      "연구 결과에 따르면, 오리너구리의 눈은 대부분의 포유류보다는 어류인 칠성장어나 먹장어, 그\n",
      "================================================================================\n",
      "검색 쿼리 문장:  로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?\n",
      "미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스\n",
      "1950년대 말 매사추세츠 공과대학교의 동아리 테크모델철도클럽에서 ‘해커’라는 용어가 처음\n",
      "1950년대 말 매사추세츠 공과대학교의 동아리 테크모델철도클럽에서 ‘해커’라는 용어가 처음\n"
     ]
    }
   ],
   "source": [
    "query = \"이번 연도에는 언제 비가 많이 올까?\"\n",
    "print(\"검색 쿼리 문장: \", query)\n",
    "results = hybrid_search(query)\n",
    "for idx, score in results[:3]:\n",
    "  print(klue_mrc_dataset['context'][idx][:50])\n",
    "\n",
    "print(\"=\" * 80)\n",
    "query = klue_mrc_dataset[3]['question'] # 로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?\n",
    "print(\"검색 쿼리 문장: \", query)\n",
    "\n",
    "results = hybrid_search(query)\n",
    "for idx, score in results[:3]:\n",
    "  print(klue_mrc_dataset['context'][idx][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
