{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: RobertaModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "## Language Model\n",
    "transformer_model = models.Transformer('klue/roberta-base')\n",
    "\n",
    "## Pooling Layer\n",
    "pooling_layer = models.Pooling(transformer_model.get_word_embedding_dimension(), pooling_mode_mean_tokens=True)\n",
    "\n",
    "## LM + Pooling\n",
    "embedding_model = SentenceTransformer(modules=[transformer_model, pooling_layer])\n",
    "print(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3ae9f948e443399eb41fc466043845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e76b45967f0410890f5f5d5b8f82d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/68.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e8735f98ed4f53b5e2be49d324a22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/11668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6196cb41532548c0b400b2a8c5f3d194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/519 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'guid': 'klue-sts-v1_train_00000', 'source': 'airbnb-rtt', 'sentence1': '숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.', 'sentence2': '숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.', 'labels': {'label': 3.7, 'real-label': 3.714285714285714, 'binary-label': 1}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "klue_sts_train = load_dataset(\"klue\", \"sts\", split=\"train\")\n",
    "klue_sts_test = load_dataset(\"klue\", \"sts\", split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guid\n",
      "klue-sts-v1_train_00000 \n",
      "\n",
      "source\n",
      "airbnb-rtt \n",
      "\n",
      "sentence1\n",
      "숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다. \n",
      "\n",
      "sentence2\n",
      "숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다. \n",
      "\n",
      "labels\n",
      "{'label': 3.7, 'real-label': 3.714285714285714, 'binary-label': 1} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = klue_sts_train[0]\n",
    "\n",
    "for key, value in sample.items():\n",
    "    print(key)\n",
    "    print(value, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "klue_sts_train = klue_sts_train.train_test_split(test_size=0.1, seed=42)\n",
    "klue_sts_train, klue_sts_eval = klue_sts_train['train'], klue_sts_train['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "def prepare_sts_examples(dataset):\n",
    "    examples = []\n",
    "    for data in dataset:\n",
    "        examples.append(InputExample(texts=[data['sentence1'], data['sentence2']], label=data['labels']['label'] / 5.0))\n",
    "\n",
    "    return examples\n",
    "\n",
    "\n",
    "train_examples = prepare_sts_examples(klue_sts_train)\n",
    "eval_examples = prepare_sts_examples(klue_sts_eval)\n",
    "test_examples = prepare_sts_examples(klue_sts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10501\n",
      "<InputExample> label: 0.0, texts: 프라하 자체가 안전한 도시이긴 하지만요.; 물론 저희가 추위를 많이 타긴 하지만요!\n"
     ]
    }
   ],
   "source": [
    "print(len(train_examples))\n",
    "\n",
    "sample = train_examples[10]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "eval_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(eval_examples)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36460670798564826"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea3ef3d7fc2499297a9133ed17b6bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e354104bb77e418eb2bcfb358963d126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981c518dca8643e9928624891c138938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4591c9e98dfa4a86826ba8ba4e906556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c669e46a62d642418463debc253c7ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec536f4d58a48ba8ee303299a0837b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "epochs = 5\n",
    "model_name = 'klue/roberta-base'\n",
    "model_save_path = f\"./output/training_sts_{model_name.replace('/', '-')}\"\n",
    "loss_func = losses.CosineSimilarityLoss(model=embedding_model)\n",
    "\n",
    "embedding_model.fit(train_objectives=[(train_dataloader, loss_func)],\n",
    "                    evaluator=eval_evaluator,\n",
    "                    epochs=epochs,\n",
    "                    evaluation_steps=1000,\n",
    "                    warmup_steps=100,\n",
    "                    output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8932227127266475"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_embedding_model = SentenceTransformer(model_save_path)\n",
    "test_evaluator(trained_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '제주도 장마 시작 … 중부는 이달 말부터', 'context': '올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2~3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다.장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20~21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24~25일이었으며 장마기간은 32일, 강수일수는 17.2일이었다.기상청은 올해 장마기간의 평균 강수량이 350~400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다.', 'news_category': '종합', 'source': 'hankyung', 'guid': 'klue-mrc-v1_train_12759', 'is_impossible': False, 'question_type': 1, 'question': '북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은?', 'answers': {'answer_start': [478, 478], 'text': ['한 달가량', '한 달']}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "klue_mrc_train = load_dataset('klue', 'mrc', split='train')\n",
    "klue_mrc_test = load_dataset('klue', 'mrc', split='validation')\n",
    "\n",
    "print(klue_mrc_train[0])\n",
    "\n",
    "df_train = klue_mrc_train.to_pandas()\n",
    "df_test = klue_mrc_test.to_pandas()\n",
    "\n",
    "df_train = df_train[['title', 'question', 'context']]\n",
    "df_test = df_test[['title', 'question', 'context']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ir_context(df):\n",
    "    irrelevant_contexts = []\n",
    "    for idx, row in df.iterrows():\n",
    "        title = row['title']\n",
    "        irrelevant_contexts.append(df.query(f\"title != '{title}'\").sample(n=1)['context'].values[0])\n",
    "    df['irrelevant_context'] = irrelevant_contexts\n",
    "    return df\n",
    "    \n",
    "df_train_ir = add_ir_context(df_train)\n",
    "df_test_ir = add_ir_context(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "제주도 장마 시작 … 중부는 이달 말부터\n",
      "\n",
      "question\n",
      "북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은?\n",
      "\n",
      "context\n",
      "올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2~3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다.장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20~21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24~25일이었으며 장마기간은 32일, 강수일수는 17.2일이었다.기상청은 올해 장마기간의 평균 강수량이 350~400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다.\n",
      "\n",
      "irrelevant_context\n",
      "에드빈 피셔(Edwin Fischer, 1886년 10월 6일 ~ 1960년 1월 24일)는 스위스에서 태어나 독일에서 활동한 피아니스트이자 지휘자이다.\n",
      "\n",
      "흔히 독일의 피아니스트라고 하나, 출생국은 스위스이다. 독일에서 주로 활약하고 바흐, 모차르트, 슈베르트의 작품에서 순수하게 독일적이고 고전적인 양식감과 내용을 부여했으므로, 20세기 독일 피아노계의 큰 인물로 꼽힌다. 그는 바젤에서 태어났으며, 고향인 바젤 음악원에서 기초교육을 받은 후 베를린으로 나와 슈테른 음악원에서 마르틴 크라우제에게서 가르침을 받았다. 그 후 모교의 교수, 다시금 베를린 고등음악원의 교수가 되었다. 또 자기가 조직한 실내 관현악단과 그 밖의 합주단 지휘자로서도 활약하였다. 그의 연주양식을 보면 템포, 리듬은 빈틈없이 꼼꼼했으며, 완급에 한도를 넘는 신축도 없었다. 그러면서 청결하고 짤막한 리듬감을 지니면서 연주했다. 또 연주에는 열이 가해지고, 기백이 따르고, 때로는 표현욕이 지나쳐서 고전양식에 파탄을 일으키기도 하였다. 바흐의 클라비어곡에서 뛰어난 연주를 보였다. 모차르트, 슈베르트의 작품 연주에도 뛰어났다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = df_train_ir.iloc[0]\n",
    "print(f\"title\\n{sample['title']}\\n\")\n",
    "print(f\"question\\n{sample['question']}\\n\")\n",
    "print(f\"context\\n{sample['context']}\\n\")\n",
    "print(f\"irrelevant_context\\n{sample['irrelevant_context']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "examples = []\n",
    "for idx, row in df_test_ir.iterrows():\n",
    "    examples.append(InputExample(texts=[row['question'], row['context']], \n",
    "                                 label=1))\n",
    "    examples.append(InputExample(texts=[row['question'], row['irrelevant_context']],\n",
    "                                 label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.826860779505915"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(examples)\n",
    "evaluator(trained_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import datasets\n",
    "\n",
    "train_samples = []\n",
    "for idx, row in df_train_ir.iterrows():\n",
    "    train_samples.append(InputExample(texts=[row['question'], row['context']]))\n",
    "\n",
    "batch_size = 16\n",
    "loader = datasets.NoDuplicatesDataLoader(train_samples, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "loss = losses.MultipleNegativesRankingLoss(trained_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f13f1a8a7c49eabbd3e7cbf8935032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560162132f1843788a53e98f93cbb99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1097 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8b4735e8e24987a5a7b59098df5db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1097 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61003f578b1740499a7a559aae2e7f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1097 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a0362c60854ce0bdbcbcb5e6418c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1097 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72034ae5b3e41a092d631e6aadc5f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1097 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 5\n",
    "save_path = \"./output/training_mrc_klue-roberta-base\"\n",
    "\n",
    "trained_embedding_model.fit(train_objectives=[(loader, loss)],\n",
    "                            epochs=epochs,\n",
    "                            warmup_steps=100,\n",
    "                            output_path=save_path,\n",
    "                            show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8599035510257997"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(trained_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "cross_model = CrossEncoder('klue/roberta-base', num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020377511284339317"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "\n",
    "ce_evaluator = CECorrelationEvaluator.from_input_examples(examples)\n",
    "ce_evaluator(cross_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = []\n",
    "for idx, row in df_train_ir.iterrows():\n",
    "    train_samples.append(InputExample(texts=[row['question'], row['context']], label=1))\n",
    "    train_samples.append(InputExample(texts=[row['question'], row['irrelevant_context']], label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6599aa85f44dd89553934c0a767eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383d5e72505e4d4cba7389191f3a8cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f401e0fd74845c2b2a41ca0811edf6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf23f582ba0434e80af03e1ae3b7a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001e2bcbeba54dd1a8edc588b7966d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5fde7d45a2479b934042511c470282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 16\n",
    "model_save_path = \"./output/training_mrc_cross-encoder-roberta-base\"\n",
    "\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "cross_model.fit(train_dataloader=train_dataloader, epochs=epochs, warmup_steps=100, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8652622896663202"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_evaluator(cross_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "klue_mrc_test = load_dataset('klue', 'mrc', split='validation')\n",
    "klue_mrc_test = klue_mrc_test.train_test_split(test_size=1000, seed=42)['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "def make_embedding_index(model, corpus):\n",
    "    embeddings = model.encode(corpus)\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "\n",
    "    return index\n",
    "\n",
    "def find_embedding_top_k(query, model, index, k):\n",
    "    query_embedding = model.encode([query])\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_question_context_pairs(question_idx, indices):\n",
    "    return [[klue_mrc_test['question'][question_idx], klue_mrc_test['context'][idx]] for idx in indices]\n",
    "\n",
    "def rerank_top_k(cross_model, question_idx, indices, k):\n",
    "    input_examples = make_question_context_pairs(question_idx, indices)\n",
    "    relevance_scores = cross_model.predict(input_examples)\n",
    "    reranked_indices = indices[np.argsort(relevance_scores)[::-1]]\n",
    "\n",
    "    return reranked_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# def evaluate_hit_rate(datasets, embedding_model, index, k=10):\n",
    "#     ## bi-encoder only\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     predictions = []\n",
    "#     for question in datasets['question']:\n",
    "#         predictions.append(find_embedding_top_k(question, embedding_model, index, k)[0])\n",
    "\n",
    "#     total_prediction_count = len(predictions)\n",
    "#     hit_count = 0\n",
    "#     questions = datasets['question']\n",
    "#     contexts = datasets['context']\n",
    "#     for idx, prediction in enumerate(predictions):\n",
    "#         for pred in prediction:\n",
    "#           if contexts[pred] == contexts[idx]:\n",
    "#             hit_count += 1\n",
    "#             break\n",
    "    \n",
    "#     end_time = time.time()\n",
    "#     return hit_count / total_prediction_count, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuned_embedding_model = SentenceTransformer('shangrilar/klue-roberta-base-klue-sts-mrc')\n",
    "# finetuned_index = make_embedding_index(finetuned_embedding_model, klue_mrc_test['context'])\n",
    "# evaluate_hit_rate(klue_mrc_test, finetuned_embedding_model, finetuned_index, 10)\n",
    "# # (0.946, 14.309881687164307)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def evaluate_hit_rate_with_rerank(datasets, embedding_model, cross_model, index, bi_k=30, cross_k=10):\n",
    "    start_time = time.time()\n",
    "\n",
    "    predictions = []\n",
    "    for question_idx, question in enumerate(tqdm(datasets['question'])):\n",
    "        indices = find_embedding_top_k(question, embedding_model, index, bi_k)[0] ## bi-encoder\n",
    "        predictions.append(rerank_top_k(cross_model, question_idx, indices, k=cross_k)) ## cross-encoder\n",
    "  \n",
    "    total_prediction_count = len(predictions)\n",
    "    hit_count = 0\n",
    "    questions = datasets['question']\n",
    "    contexts = datasets['context']\n",
    "    for idx, prediction in enumerate(predictions):\n",
    "        for pred in prediction:\n",
    "            if contexts[pred] == contexts[idx]:\n",
    "                hit_count += 1\n",
    "                break\n",
    "    end_time = time.time()\n",
    "    return hit_count / total_prediction_count, end_time - start_time, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10523f8307ec40fbade05caf98aec996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.978, 287.2874445915222)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = make_embedding_index(trained_embedding_model, klue_mrc_test['context'])\n",
    "hit_rate, cosumed_time, predictions = evaluate_hit_rate_with_rerank(klue_mrc_test, trained_embedding_model, cross_model, index, bi_k=30, cross_k=10)\n",
    "hit_rate, cosumed_time\n",
    "# (0.973, 1103.055629491806)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
