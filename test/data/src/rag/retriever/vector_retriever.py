import os
import faiss
import numpy as np

from datetime import datetime
from fastapi import APIRouter, Request

from langchain_community.vectorstores import FAISS
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain.docstore.document import Document

from langchain_openai import OpenAIEmbeddings
from langchain_huggingface.embeddings import HuggingFaceEmbeddings

from app.utils.logging import logger
from src.utils.config_utils import save_config
from src.rag.data.dataset import load_documents_from_db

class VectorStore:
    def __init__(self, cfg):
        """
        FAISS ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ë° ë¡œë“œ
        """
        self.cfg = cfg
        if self.cfg['provider'] == "openai":
            self.embed_model = OpenAIEmbeddings(model=self.cfg['model_name'], api_key=self.cfg['openai_api_key'])

        elif self.cfg['provider'] == "huggingface":
            self.embed_model = HuggingFaceEmbeddings(model_name=self.cfg['model_name'], model_kwargs=self.cfg['model_kwargs'], encode_kwargs=self.cfg['encode_kwargs'])

        self.vector_db = None

    
    def create_vector_db(self, index_type):
        logger.info(f"ğŸš€ ë²¡í„° DB ì´ˆê¸°í™” ì¤‘")
        sample_query = "ê¸°ì—…ì˜ ë¹„ì „ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”."

        if index_type == "L2": ## L2 Distance(Euclidean Distance)
            index = faiss.IndexFlatL2(len(self.embed_model.embed_query(sample_query)))

        elif index_type == "IP": ## Inner Product
            index = faiss.IndexFlatIP(len(self.embed_model.embed_query(sample_query)))

        elif index_type == "HNSW":## ANN -> Hierarchical Navigable Small World
            index = faiss.IndexHNSWFlat(len(self.embed_model.embed_query(sample_query)))

        else:
            raise ValueError("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” index_type")

        vector_db = FAISS(
            embedding_function=self.embed_model,
            index=index,
            docstore=InMemoryDocstore(),
            index_to_docstore_id={},
        )
        logger.info("âœ… ë²¡í„° DB ì´ˆê¸°í™” ì™„ë£Œ")

        documents = load_documents_from_db(db_name='culture_db', collection_name='company_homepage')
        logger.info(f"ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ : {len(documents)}")

        if documents:
            vector_db.add_documents(documents)
            logger.info("âœ… ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ")

        self.vector_db = vector_db

        return vector_db
    

    def save_vector_db(self, vector_db):
        now = datetime.now().strftime("%Y-%m-%d-%H-%M-%S")
        save_path = f"{self.cfg['index_save_path']}/{now}"
        
        os.makedirs(save_path, exist_ok=True)

        vector_db.save_local(save_path)
        save_config(self.cfg, f"{save_path}/config.yaml")

        logger.info(f"âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ. ì €ì¥ ê²½ë¡œ: {save_path}")


    def load_vector_db(self, index_file_path):
        """
        ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¡œë“œí•˜ê±°ë‚˜, ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš° ìƒˆë¡œìš´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì¤‘... (ê²½ë¡œ: {index_file_path})")

        # 1. ì¸ë±ìŠ¤ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not os.path.exists(index_file_path):
            logger.warning(f"âŒ ì¸ë±ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {index_file_path}")
            logger.info("ğŸš€ ìƒˆë¡œìš´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
            
            # 2. ìƒˆë¡œìš´ ë²¡í„° DB ìƒì„±
            vector_db = self.create_vector_db(index_type=self.cfg['index_type'])

            # 3. ìƒˆë¡œìš´ ë²¡í„° DB ì €ì¥
            self.save_vector_db(vector_db)

            self.vector_db = vector_db
            logger.info("âœ… ìƒˆë¡œìš´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„± ë° ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return vector_db

        try:
            # 4. ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ
            vector_db = FAISS.load_local(index_file_path, embeddings=self.embed_model, allow_dangerous_deserialization=True)

            # 5. ê¸°ì¡´ ì¸ë±ìŠ¤ì˜ ì°¨ì› í™•ì¸
            dim = vector_db.index.d

            # 6. ìƒˆë¡œìš´ ë¹ˆ ì¸ë±ìŠ¤ ìƒì„±
            if isinstance(vector_db.index, faiss.IndexFlatL2):
                new_index = faiss.IndexFlatL2(dim)
            elif isinstance(vector_db.index, faiss.IndexFlatIP):
                new_index = faiss.IndexFlatIP(dim)
            elif isinstance(vector_db.index, faiss.IndexHNSWFlat):
                new_index = faiss.IndexHNSWFlat(dim, 32)  # HNSW M íŒŒë¼ë¯¸í„° ê¸°ë³¸ê°’ 32
            else:
                raise ValueError("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¸ë±ìŠ¤ íƒ€ì…ì…ë‹ˆë‹¤.")

            # 7. ê¸°ì¡´ ë²¡í„°ë“¤ì„ ìƒˆ ì¸ë±ìŠ¤ë¡œ ë³µì‚¬
            if vector_db.index.ntotal > 0:
                vectors = vector_db.index.reconstruct_n(0, vector_db.index.ntotal)
                new_index.add(vectors)

            # 8. ìƒˆ ì¸ë±ìŠ¤ë¡œ êµì²´
            vector_db.index = new_index
            logger.info("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ")

            self.vector_db = vector_db
            return vector_db

        except Exception as e:
            logger.error(f"âŒ Vector DB Initialization Error: {str(e)}")
            raise RuntimeError(f"Vector DB ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        

    def search_company(self, company_name):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ì´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ëª‡ ê°œì˜ ë¬¸ì„œê°€ ìˆëŠ”ì§€ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ” '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        count = 0

        # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë“  ë¬¸ì„œë¥¼ ê²€ìƒ‰
        for doc_id, document in self.vector_db.docstore._dict.items():
            if isinstance(document, Document) and document.metadata.get("company_name") == company_name:
                count += 1

        logger.info(f"ğŸ” '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ ê°œìˆ˜: {count}")
        return count


    def delete_company(self, company_name):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  ë¬¸ì„œë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚­ì œí•˜ê³ , ì‚­ì œ ì—¬ë¶€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ—‘ï¸ '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ ì‚­ì œ ì¤‘...")
        to_delete = []

        # ì‚­ì œí•  ë¬¸ì„œ ìˆ˜ì§‘
        for doc_id, document in self.vector_db.docstore._dict.items():
            if isinstance(document, Document) and document.metadata.get("company_name") == company_name:
                to_delete.append(doc_id)

        # ë¬¸ì„œ ì‚­ì œ
        for doc_id in to_delete:
            del self.vector_db.docstore._dict[doc_id]

        logger.info(f"âœ… '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ {len(to_delete)}ê°œ ì‚­ì œ ì™„ë£Œ")
        return len(to_delete) > 0


    def get_company_documents(self, company_name):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ì„ ê°€ì§„ ëª¨ë“  ë¬¸ì„œë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ” Vector DBì—ì„œ '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        results = []

        # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë“  ë¬¸ì„œë¥¼ ê²€ìƒ‰
        for doc_id, document in self.vector_db.docstore._dict.items():
            if isinstance(document, Document) and document.metadata.get("company_name") == company_name:
                results.append({
                    "url": document.metadata.get("url"),
                    "text": document.page_content
                })

        logger.info(f"ğŸ” ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œì˜ ë¬¸ì„œ ë°œê²¬")
        return results
    

    def search_document(self, company_name, url):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ê³¼ URLì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ” '{company_name}' íšŒì‚¬ì˜ URL '{url}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        
        # íšŒì‚¬ëª…ìœ¼ë¡œ ë¬¸ì„œ ê²€ìƒ‰
        documents = self.get_company_documents(company_name)
        
        # URLì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œ ì°¾ê¸°
        for document in documents:
            if document['url'] == url:
                logger.info(f"âœ… ë¬¸ì„œ ë°œê²¬: {document}")
                return document
        
        logger.warning(f"'{company_name}' íšŒì‚¬ì˜ URL '{url}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None


    def update_document(self, company_name, url, new_text=None, new_url=None):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ê³¼ URLì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ”„ '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì¤‘... (URL: {url})")
        
        # ê¸°ì¡´ ë¬¸ì„œì˜ docstore ID ì°¾ê¸°
        doc_id = None
        for id_, doc in self.vector_db.docstore._dict.items():
            if (isinstance(doc, Document) and 
                doc.metadata.get("company_name") == company_name and 
                doc.metadata.get("url") == url):
                doc_id = id_
                break
        
        if doc_id is None:
            logger.warning(f"'{company_name}' íšŒì‚¬ì˜ URL '{url}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # 1. Docstoreì—ì„œ ë¬¸ì„œ ì‚­ì œ
        original_doc = self.vector_db.docstore._dict.pop(doc_id)
        
        # 2. FAISS ì¸ë±ìŠ¤ì—ì„œ ë²¡í„° ì‚­ì œ
        # docstore IDë¥¼ FAISS ì¸ë±ìŠ¤ IDë¡œ ë³€í™˜
        index_id = list(self.vector_db.index_to_docstore_id.keys())[
            list(self.vector_db.index_to_docstore_id.values()).index(doc_id)
        ]
        self.vector_db.index_to_docstore_id.pop(index_id)
        self.vector_db.index.remove_ids(np.array([index_id]))

        # 3. ìƒˆë¡œìš´ ë¬¸ì„œ ìƒì„±
        updated_text = new_text if new_text else original_doc.page_content
        updated_url = new_url if new_url else url
        
        updated_document = Document(
            page_content=updated_text,
            metadata={"company_name": company_name, "url": updated_url}
        )

        # 4. ìƒˆë¡œìš´ ë¬¸ì„œ ì¶”ê°€
        self.vector_db.add_documents([updated_document])
        
        logger.info("âœ… ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        return updated_document


    def delete_document(self, company_name, url):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ê³¼ URLì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚­ì œí•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ—‘ï¸ '{company_name}' íšŒì‚¬ì˜ URL '{url}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œ ì‚­ì œ ì¤‘...")
        
        # docstoreì—ì„œ ë¬¸ì„œ ID ì°¾ê¸°
        doc_id = None
        for id_, doc in self.vector_db.docstore._dict.items():
            if (isinstance(doc, Document) and 
                doc.metadata.get("company_name") == company_name and 
                doc.metadata.get("url") == url):
                doc_id = id_
                break
        
        if doc_id is None:
            logger.warning(f"'{company_name}' íšŒì‚¬ì˜ URL '{url}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        try:
            # 1. Docstoreì—ì„œ ë¬¸ì„œ ì‚­ì œ
            self.vector_db.docstore._dict.pop(doc_id)
            
            # 2. FAISS ì¸ë±ìŠ¤ì—ì„œ ë²¡í„° ì‚­ì œ
            # docstore IDë¥¼ FAISS ì¸ë±ìŠ¤ IDë¡œ ë³€í™˜
            index_id = list(self.vector_db.index_to_docstore_id.keys())[
                list(self.vector_db.index_to_docstore_id.values()).index(doc_id)
            ]
            self.vector_db.index_to_docstore_id.pop(index_id)
            self.vector_db.index.remove_ids(np.array([index_id]))
            
            logger.info(f"âœ… ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ (doc_id: {doc_id}, index_id: {index_id})")
            return True
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
    

    def similarity_search_with_score(self, query: str, filter: str = None, fetch_k: int = None):
        """
        ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  scoreë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            query (str): ê²€ìƒ‰í•  ì¿¼ë¦¬ ë¬¸ìì—´
            filter (str, optional): íšŒì‚¬ëª…ìœ¼ë¡œ í•„í„°ë§í•  ê²½ìš° ì‚¬ìš©. ì˜ˆ: "samsung"
            fetch_k (int, optional): ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜. ê¸°ë³¸ê°’ì€ kì˜ 2ë°°
            
        Returns:
            List[Tuple[Document, float]]: ë¬¸ì„œì™€ ìœ ì‚¬ë„ ì ìˆ˜ íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
        """
        k = int(self.cfg.get('top_k', 10))
        
        # fetch_kê°€ Noneì´ë©´ kì˜ 2ë°°ë¡œ ì„¤ì •
        if fetch_k is None:
            fetch_k = k * 2
            
        # filterê°€ ìˆìœ¼ë©´ íšŒì‚¬ëª…ìœ¼ë¡œ í•„í„° ì¡°ê±´ ìƒì„±
        filter_dict = None
        if filter:
            filter_dict = {"company_name": filter}
            
        results = self.vector_db.similarity_search_with_score(
            query,
            k=k,
            filter=filter_dict,
            fetch_k=fetch_k
        )

        # numpy.float32 â†’ float ë³€í™˜ ë° scoreë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        results = sorted([(doc, float(score)) for doc, score in results], key=lambda x: x[1], reverse=True)

        return results


    def similarity_search_with_relevance_scores(self, query: str, filter: str = None, fetch_k: int = None):
        """
        ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  relevance scoreë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            query (str): ê²€ìƒ‰í•  ì¿¼ë¦¬ ë¬¸ìì—´
            filter (str, optional): íšŒì‚¬ëª…ìœ¼ë¡œ í•„í„°ë§í•  ê²½ìš° ì‚¬ìš©. ì˜ˆ: "samsung"
            fetch_k (int, optional): ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜. ê¸°ë³¸ê°’ì€ kì˜ 2ë°°
            
        Returns:
            List[Tuple[Document, float]]: ë¬¸ì„œì™€ ê´€ë ¨ë„ ì ìˆ˜ íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸
        """
        k = int(self.cfg.get('top_k', 10))
        
        # fetch_kê°€ Noneì´ë©´ kì˜ 2ë°°ë¡œ ì„¤ì •
        if fetch_k is None:
            fetch_k = k * 2
            
        # filterê°€ ìˆìœ¼ë©´ íšŒì‚¬ëª…ìœ¼ë¡œ í•„í„° ì¡°ê±´ ìƒì„±
        filter_dict = None
        if filter:
            filter_dict = {"company_name": filter}
            
        results = self.vector_db.similarity_search_with_relevance_scores(
            query,
            k=k,
            filter=filter_dict,
            fetch_k=fetch_k
        )

        # numpy.float32 â†’ float ë³€í™˜ ë° scoreë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        results = sorted([(doc, float(score)) for doc, score in results], key=lambda x: x[1], reverse=True)

        return results

    def clear_all_documents(self):
        """
        ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
        """
        logger.info("ğŸ—‘ï¸ ë²¡í„° DBì˜ ëª¨ë“  ë¬¸ì„œ ì‚­ì œ ì¤‘...")

        # ëª¨ë“  ë¬¸ì„œ ID ìˆ˜ì§‘
        all_doc_ids = list(self.vector_db.docstore._dict.keys())

        # ëª¨ë“  ë¬¸ì„œ ì‚­ì œ
        for doc_id in all_doc_ids:
            # 1. Docstoreì—ì„œ ë¬¸ì„œ ì‚­ì œ
            self.vector_db.docstore._dict.pop(doc_id, None)
            
            # 2. FAISS ì¸ë±ìŠ¤ì—ì„œ ë²¡í„° ì‚­ì œ
            if doc_id in self.vector_db.index_to_docstore_id.values():
                index_id = list(self.vector_db.index_to_docstore_id.keys())[
                    list(self.vector_db.index_to_docstore_id.values()).index(doc_id)
                ]
                self.vector_db.index_to_docstore_id.pop(index_id, None)
                self.vector_db.index.remove_ids(np.array([index_id]))

        logger.info("âœ… ë²¡í„° DBì˜ ëª¨ë“  ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ")