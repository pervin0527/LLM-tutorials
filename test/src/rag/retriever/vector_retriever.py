import os
import faiss

from datetime import datetime
from fastapi import APIRouter, Request

from langchain_community.vectorstores import FAISS
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain.docstore.document import Document

from langchain_openai import OpenAIEmbeddings
from langchain_huggingface.embeddings import HuggingFaceEmbeddings

from app.utils.logging import logger
from src.utils.config_utils import save_config
from src.rag.data.dataset import load_documents_from_db

class VectorStore:
    def __init__(self, cfg):
        """
        FAISS ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ë° ë¡œë“œ
        """
        self.cfg = cfg
        if self.cfg['provider'] == "openai":
            self.embed_model = OpenAIEmbeddings(model=self.cfg['model_name'], api_key=self.cfg['openai_api_key'])

        elif self.cfg['provider'] == "huggingface":
            self.embed_model = HuggingFaceEmbeddings(model_name=self.cfg['model_name'], model_kwargs=self.cfg['model_kwargs'], encode_kwargs=self.cfg['encode_kwargs'])

        self.vector_db = None

    
    def create_vector_db(self, index_type):
        logger.info(f"ğŸš€ ë²¡í„° DB ì´ˆê¸°í™” ì¤‘... (íƒ€ì…: {index_type})")
        sample_query = "ê¸°ì—…ì˜ ë¹„ì „ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”."

        if index_type == "L2": ## L2 Distance(Euclidean Distance)
            index = faiss.IndexFlatL2(len(self.embed_model.embed_query(sample_query)))

        elif index_type == "IP": ## Inner Product
            index = faiss.IndexFlatIP(len(self.embed_model.embed_query(sample_query)))

        elif index_type == "HNSW":## ANN -> Hierarchical Navigable Small World
            index = faiss.IndexHNSWFlat(len(self.embed_model.embed_query(sample_query)))

        else:
            raise ValueError("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” index_type")

        vector_db = FAISS(
            embedding_function=self.embed_model,
            index=index,
            docstore=InMemoryDocstore(),
            index_to_docstore_id={},
        )
        logger.info("âœ… ë²¡í„° DB ì´ˆê¸°í™” ì™„ë£Œ")

        documents = load_documents_from_db()
        logger.info(f"ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ : {len(documents)}")
        
        vector_db.add_documents(documents)
        logger.info("âœ… ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ")

        self.vector_db = vector_db

        return vector_db
    

    def save_vector_db(self, vector_db):
        now = datetime.now().strftime("%Y-%m-%d-%H-%M-%S")
        save_path = f"{self.cfg['index_save_path']}/{now}"
        
        os.makedirs(save_path, exist_ok=True)

        vector_db.save_local(save_path)
        save_config(self.cfg, f"{save_path}/config.yaml")

        logger.info(f"âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ. ì €ì¥ ê²½ë¡œ: {save_path}")


    def load_vector_db(self, index_file_path, embed_model):
        logger.info(f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì¤‘... (ê²½ë¡œ: {index_file_path})")
        vector_db = FAISS.load_local(index_file_path, embeddings=embed_model, allow_dangerous_deserialization=True)
        logger.info("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ")

        self.vector_db = vector_db
        return vector_db
       

    def search_company(self, company_name):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ì´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ëª‡ ê°œì˜ ë¬¸ì„œê°€ ìˆëŠ”ì§€ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ” '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        count = 0

        # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë“  ë¬¸ì„œë¥¼ ê²€ìƒ‰
        for doc_id, document in self.vector_db.docstore._dict.items():
            if isinstance(document, Document) and document.metadata.get("company_name") == company_name:
                count += 1

        logger.info(f"ğŸ” '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ ê°œìˆ˜: {count}")
        return count


    def delete_company(self, company_name):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  ë¬¸ì„œë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚­ì œí•˜ê³ , ì‚­ì œ ì—¬ë¶€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ—‘ï¸ '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ ì‚­ì œ ì¤‘...")
        to_delete = []

        # ì‚­ì œí•  ë¬¸ì„œ ìˆ˜ì§‘
        for doc_id, document in self.vector_db.docstore._dict.items():
            if isinstance(document, Document) and document.metadata.get("company_name") == company_name:
                to_delete.append(doc_id)

        # ë¬¸ì„œ ì‚­ì œ
        for doc_id in to_delete:
            del self.vector_db.docstore._dict[doc_id]

        logger.info(f"âœ… '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ {len(to_delete)}ê°œ ì‚­ì œ ì™„ë£Œ")
        return len(to_delete) > 0


    def get_company_documents(self, company_name):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ì„ ê°€ì§„ ëª¨ë“  ë¬¸ì„œë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ” Vector DBì—ì„œ '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        results = []

        # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë“  ë¬¸ì„œë¥¼ ê²€ìƒ‰
        for doc_id, document in self.vector_db.docstore._dict.items():
            if isinstance(document, Document) and document.metadata.get("company_name") == company_name:
                results.append({
                    "url": document.metadata.get("url"),
                    "text": document.page_content
                })

        logger.info(f"ğŸ” ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œì˜ ë¬¸ì„œ ë°œê²¬")
        return results
    

    def search_document(self, company_name, url):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ê³¼ URLì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ” '{company_name}' íšŒì‚¬ì˜ URL '{url}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        
        # íšŒì‚¬ëª…ìœ¼ë¡œ ë¬¸ì„œ ê²€ìƒ‰
        documents = self.get_company_documents(company_name)
        
        # URLì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œ ì°¾ê¸°
        for document in documents:
            if document['url'] == url:
                logger.info(f"âœ… ë¬¸ì„œ ë°œê²¬: {document}")
                return document
        
        logger.warning(f"'{company_name}' íšŒì‚¬ì˜ URL '{url}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None


    def update_document(self, company_name, url, new_text=None, new_url=None):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ê³¼ URLì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ”„ '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì¤‘... (URL: {url})")
        
        # íšŒì‚¬ëª…ê³¼ URLë¡œ ë¬¸ì„œ ê²€ìƒ‰
        document = self.search_document(company_name, url)
        
        if document:
            original_url = document['url']
            
            if new_text:
                document['text'] = new_text
                logger.info(f"ë¬¸ì„œ ë‚´ìš©ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤. (URL: {original_url})")
            
            if new_url:
                document['url'] = new_url
                logger.info(f"ë¬¸ì„œ URLì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤. (ìƒˆ URL: {new_url})")
            
            # ì—…ë°ì´íŠ¸ëœ ë¬¸ì„œë¥¼ Document ê°ì²´ë¡œ ë³€í™˜í•˜ì—¬ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ë°˜ì˜
            updated_document = Document(
                page_content=document['text'],
                metadata={"company_name": company_name, "url": document['url']}
            )
            self.vector_db.docstore._dict.pop(original_url, None)  # ê¸°ì¡´ URLë¡œ ì €ì¥ëœ ë¬¸ì„œ ì œê±°
            self.vector_db.docstore._dict[document['url']] = updated_document  # ìƒˆë¡œìš´ URLë¡œ ë¬¸ì„œ ì €ì¥
            logger.info("âœ… ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            return document
        
        logger.warning(f"'{company_name}' íšŒì‚¬ì˜ URL '{url}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None


    def delete_document(self, company_name, url):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ê³¼ URLì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚­ì œí•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ—‘ï¸ '{company_name}' íšŒì‚¬ì˜ URL '{url}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œ ì‚­ì œ ì¤‘...")
        
        # íšŒì‚¬ëª…ê³¼ URLë¡œ ë¬¸ì„œ ê²€ìƒ‰
        document = self.search_document(company_name, url)
        
        if document:
            original_url = document['url']
            # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¬¸ì„œ ì‚­ì œ
            self.vector_db.docstore._dict.pop(original_url, None)
            logger.info(f"âœ… ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ: {original_url}")
            return True
        
        logger.warning(f"'{company_name}' íšŒì‚¬ì˜ URL '{url}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    

    def similarity_search_with_score(self, query):
        k = int(self.cfg.get('top_k', 10))
        fetch_k = k * 2

        results = self.vector_db.similarity_search_with_score(query, k=k)

        # numpy.float32 â†’ float ë³€í™˜
        results = [(doc, float(score)) for doc, score in results]

        return results
        
    def similarity_search_with_relevance_scores(self, query):
        k = int(self.cfg.get('top_k', 10))
        fetch_k = k * 2

        results = self.vector_db.similarity_search_with_relevance_scores(query, k=k)

        # numpy.float32 â†’ float ë³€í™˜
        results = [(doc, float(score)) for doc, score in results]

        return results
