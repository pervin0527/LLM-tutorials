import os
import faiss
import numpy as np

from datetime import datetime
from fastapi import APIRouter, Request

from langchain_community.vectorstores import FAISS
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain.docstore.document import Document

from langchain_openai import OpenAIEmbeddings
from langchain_huggingface.embeddings import HuggingFaceEmbeddings

from app.utils.logging import logger
from src.utils.config_utils import save_config
from src.rag.data.dataset import load_documents_from_db

class VectorStore:
    def __init__(self, cfg):
        """
        FAISS ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ë° ë¡œë“œ
        """
        self.cfg = cfg
        if self.cfg['provider'] == "openai":
            self.embed_model = OpenAIEmbeddings(model=self.cfg['model_name'], api_key=self.cfg['openai_api_key'])

        elif self.cfg['provider'] == "huggingface":
            self.embed_model = HuggingFaceEmbeddings(model_name=self.cfg['model_name'], model_kwargs=self.cfg['model_kwargs'], encode_kwargs=self.cfg['encode_kwargs'])

        self.vector_db = None

    
    def create_vector_db(self, index_type):
        logger.info(f"ğŸš€ ë²¡í„° DB ì´ˆê¸°í™” ì¤‘")
        sample_query = "ê¸°ì—…ì˜ ë¹„ì „ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”."

        if index_type == "L2": ## L2 Distance(Euclidean Distance)
            index = faiss.IndexFlatL2(len(self.embed_model.embed_query(sample_query)))

        elif index_type == "IP": ## Inner Product
            index = faiss.IndexFlatIP(len(self.embed_model.embed_query(sample_query)))

        elif index_type == "HNSW":## ANN -> Hierarchical Navigable Small World
            index = faiss.IndexHNSWFlat(len(self.embed_model.embed_query(sample_query)))

        else:
            raise ValueError("âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” index_type")

        vector_db = FAISS(
            embedding_function=self.embed_model,
            index=index,
            docstore=InMemoryDocstore(),
            index_to_docstore_id={},
        )
        logger.info("âœ… ë²¡í„° DB ì´ˆê¸°í™” ì™„ë£Œ")

        documents = load_documents_from_db()
        logger.info(f"ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ : {len(documents)}")
        
        vector_db.add_documents(documents)
        logger.info("âœ… ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ")

        self.vector_db = vector_db

        return vector_db
    

    def save_vector_db(self, vector_db):
        now = datetime.now().strftime("%Y-%m-%d-%H-%M-%S")
        save_path = f"{self.cfg['index_save_path']}/{now}"
        
        os.makedirs(save_path, exist_ok=True)

        vector_db.save_local(save_path)
        save_config(self.cfg, f"{save_path}/config.yaml")

        logger.info(f"âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ. ì €ì¥ ê²½ë¡œ: {save_path}")


    def load_vector_db(self, index_file_path, embed_model):
        logger.info(f"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì¤‘... (ê²½ë¡œ: {index_file_path})")
        vector_db = FAISS.load_local(index_file_path, embeddings=embed_model, allow_dangerous_deserialization=True)
        logger.info("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ")

        self.vector_db = vector_db
        return vector_db
       

    def search_company(self, company_name):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ì´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ëª‡ ê°œì˜ ë¬¸ì„œê°€ ìˆëŠ”ì§€ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ” '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        count = 0

        # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë“  ë¬¸ì„œë¥¼ ê²€ìƒ‰
        for doc_id, document in self.vector_db.docstore._dict.items():
            if isinstance(document, Document) and document.metadata.get("company_name") == company_name:
                count += 1

        logger.info(f"ğŸ” '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ ê°œìˆ˜: {count}")
        return count


    def delete_company(self, company_name):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  ë¬¸ì„œë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚­ì œí•˜ê³ , ì‚­ì œ ì—¬ë¶€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ—‘ï¸ '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ ì‚­ì œ ì¤‘...")
        to_delete = []

        # ì‚­ì œí•  ë¬¸ì„œ ìˆ˜ì§‘
        for doc_id, document in self.vector_db.docstore._dict.items():
            if isinstance(document, Document) and document.metadata.get("company_name") == company_name:
                to_delete.append(doc_id)

        # ë¬¸ì„œ ì‚­ì œ
        for doc_id in to_delete:
            del self.vector_db.docstore._dict[doc_id]

        logger.info(f"âœ… '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ {len(to_delete)}ê°œ ì‚­ì œ ì™„ë£Œ")
        return len(to_delete) > 0


    def get_company_documents(self, company_name):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ì„ ê°€ì§„ ëª¨ë“  ë¬¸ì„œë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ” Vector DBì—ì„œ '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        results = []

        # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë“  ë¬¸ì„œë¥¼ ê²€ìƒ‰
        for doc_id, document in self.vector_db.docstore._dict.items():
            if isinstance(document, Document) and document.metadata.get("company_name") == company_name:
                results.append({
                    "url": document.metadata.get("url"),
                    "text": document.page_content
                })

        logger.info(f"ğŸ” ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œì˜ ë¬¸ì„œ ë°œê²¬")
        return results
    

    def search_document(self, company_name, url):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ê³¼ URLì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ” '{company_name}' íšŒì‚¬ì˜ URL '{url}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        
        # íšŒì‚¬ëª…ìœ¼ë¡œ ë¬¸ì„œ ê²€ìƒ‰
        documents = self.get_company_documents(company_name)
        
        # URLì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œ ì°¾ê¸°
        for document in documents:
            if document['url'] == url:
                logger.info(f"âœ… ë¬¸ì„œ ë°œê²¬: {document}")
                return document
        
        logger.warning(f"'{company_name}' íšŒì‚¬ì˜ URL '{url}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None


    def update_document(self, company_name, url, new_text=None, new_url=None):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ê³¼ URLì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ”„ '{company_name}' íšŒì‚¬ì˜ ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì¤‘... (URL: {url})")
        
        # ê¸°ì¡´ ë¬¸ì„œì˜ docstore ID ì°¾ê¸°
        doc_id = None
        for id_, doc in self.vector_db.docstore._dict.items():
            if (isinstance(doc, Document) and 
                doc.metadata.get("company_name") == company_name and 
                doc.metadata.get("url") == url):
                doc_id = id_
                break
        
        if doc_id is None:
            logger.warning(f"'{company_name}' íšŒì‚¬ì˜ URL '{url}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # 1. Docstoreì—ì„œ ë¬¸ì„œ ì‚­ì œ
        original_doc = self.vector_db.docstore._dict.pop(doc_id)
        
        # 2. FAISS ì¸ë±ìŠ¤ì—ì„œ ë²¡í„° ì‚­ì œ
        # docstore IDë¥¼ FAISS ì¸ë±ìŠ¤ IDë¡œ ë³€í™˜
        index_id = list(self.vector_db.index_to_docstore_id.keys())[
            list(self.vector_db.index_to_docstore_id.values()).index(doc_id)
        ]
        self.vector_db.index_to_docstore_id.pop(index_id)
        self.vector_db.index.remove_ids(np.array([index_id]))

        # 3. ìƒˆë¡œìš´ ë¬¸ì„œ ìƒì„±
        updated_text = new_text if new_text else original_doc.page_content
        updated_url = new_url if new_url else url
        
        updated_document = Document(
            page_content=updated_text,
            metadata={"company_name": company_name, "url": updated_url}
        )

        # 4. ìƒˆë¡œìš´ ë¬¸ì„œ ì¶”ê°€
        self.vector_db.add_documents([updated_document])
        
        logger.info("âœ… ë¬¸ì„œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        return updated_document


    def delete_document(self, company_name, url):
        """
        ì£¼ì–´ì§„ íšŒì‚¬ëª…ê³¼ URLì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚­ì œí•©ë‹ˆë‹¤.
        """
        logger.info(f"ğŸ—‘ï¸ '{company_name}' íšŒì‚¬ì˜ URL '{url}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œ ì‚­ì œ ì¤‘...")
        
        # docstoreì—ì„œ ë¬¸ì„œ ID ì°¾ê¸°
        doc_id = None
        for id_, doc in self.vector_db.docstore._dict.items():
            if (isinstance(doc, Document) and 
                doc.metadata.get("company_name") == company_name and 
                doc.metadata.get("url") == url):
                doc_id = id_
                break
        
        if doc_id is None:
            logger.warning(f"'{company_name}' íšŒì‚¬ì˜ URL '{url}'ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        try:
            # 1. Docstoreì—ì„œ ë¬¸ì„œ ì‚­ì œ
            self.vector_db.docstore._dict.pop(doc_id)
            
            # 2. FAISS ì¸ë±ìŠ¤ì—ì„œ ë²¡í„° ì‚­ì œ
            # docstore IDë¥¼ FAISS ì¸ë±ìŠ¤ IDë¡œ ë³€í™˜
            index_id = list(self.vector_db.index_to_docstore_id.keys())[
                list(self.vector_db.index_to_docstore_id.values()).index(doc_id)
            ]
            self.vector_db.index_to_docstore_id.pop(index_id)
            self.vector_db.index.remove_ids(np.array([index_id]))
            
            logger.info(f"âœ… ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ (doc_id: {doc_id}, index_id: {index_id})")
            return True
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
    

    def similarity_search_with_score(self, query):
        k = int(self.cfg.get('top_k', 10))
        fetch_k = k * 2

        results = self.vector_db.similarity_search_with_score(query, k=k)

        # numpy.float32 â†’ float ë³€í™˜ ë° scoreë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        results = sorted([(doc, float(score)) for doc, score in results], key=lambda x: x[1], reverse=True)

        return results
        
    def similarity_search_with_relevance_scores(self, query):
        k = int(self.cfg.get('top_k', 10))
        fetch_k = k * 2

        results = self.vector_db.similarity_search_with_relevance_scores(query, k=k)

        # numpy.float32 â†’ float ë³€í™˜ ë° scoreë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        results = sorted([(doc, float(score)) for doc, score in results], key=lambda x: x[1], reverse=True)

        return results
